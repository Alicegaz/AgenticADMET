{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from train import get_dataset\n",
    "from dataset.polaris_admet_dataset import load_polaris_dataset, SYSTEM_PROMPT, problem_template\n",
    "from dataset import validate_dataset\n",
    "import numpy as np\n",
    "from latex2sympy2_extended import NormalizationConfig\n",
    "from math_verify import LatexExtractionConfig, parse\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    PreTrainedTokenizer\n",
    ")\n",
    "import torch\n",
    "from trl import ModelConfig\n",
    "from munch import Munch\n",
    "from functools import partial\n",
    "import hashlib\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import default_data_collator\n",
    "from pathlib import Path\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_CHAT_TEMPLATE = \"{% for message in messages %}\\n{% if message['role'] == 'user' %}\\n{{ '<|user|>\\n' + message['content'] + eos_token }}\\n{% elif message['role'] == 'system' %}\\n{{ '<|system|>\\n' + message['content'] + eos_token }}\\n{% elif message['role'] == 'assistant' %}\\n{{ '<|assistant|>\\n'  + message['content'] + eos_token }}\\n{% endif %}\\n{% if loop.last and add_generation_prompt %}\\n{{ '<|assistant|>' }}\\n{% endif %}\\n{% endfor %}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mae(contents, smiles, solutions):\n",
    "    if solutions is None:\n",
    "        return [0.5] * len(contents) # Return neutral reward if no solution\n",
    "    smiles2conts = defaultdict(list)\n",
    "    for content, gold_val, smiles_i in zip(contents, solutions, smiles):\n",
    "        answer_val = None\n",
    "        if gold_val is not None:\n",
    "            answer_parsed = parse(\n",
    "                content,\n",
    "                extraction_config=[\n",
    "                    LatexExtractionConfig(\n",
    "                        normalization_config=NormalizationConfig(\n",
    "                            nits=False,\n",
    "                            malformed_operators=False,\n",
    "                            basic_latex=True,\n",
    "                            equations=True,\n",
    "                            boxed=\"all\",\n",
    "                            units=True,\n",
    "                        ),\n",
    "                        boxed_match_priority=0,\n",
    "                        try_extract_without_anchor=False,\n",
    "                    )\n",
    "                ],\n",
    "                extraction_mode=\"first_match\",\n",
    "            )\n",
    "\n",
    "            if len(answer_parsed) > 0 and not isinstance(answer_parsed[0], str):\n",
    "                answer_val = float(answer_parsed[0])\n",
    "        \n",
    "        smiles_hash = hashlib.blake2b(smiles_i.encode('utf-8'), digest_size=4).hexdigest()\n",
    "        smiles2conts[smiles_hash].append({\n",
    "                       \"answer_val\": answer_val\n",
    "                       }) \n",
    "    median_maes = []\n",
    "    for k, v in smiles2conts.items():\n",
    "        answers_g = [v_i[\"answer_val\"] for v_i in v]\n",
    "        answers_g = [float(v_i) for v_i in answers_g if v_i is not None]\n",
    "        answer_median = np.median(answers_g)\n",
    "        mae_median = np.median(np.abs(float(v[0][\"gold_val\"]) - answer_median))\n",
    "        median_maes.append(mae_median)\n",
    "    return median_maes\n",
    "\n",
    "def compute_mae_v2(content, gold_val):\n",
    "    answer_val = None\n",
    "    if gold_val is not None:\n",
    "        answer_parsed = parse(\n",
    "            content,\n",
    "            extraction_config=[\n",
    "                LatexExtractionConfig(\n",
    "                    normalization_config=NormalizationConfig(\n",
    "                        nits=False,\n",
    "                        malformed_operators=False,\n",
    "                        basic_latex=True,\n",
    "                        equations=True,\n",
    "                        boxed=\"all\",\n",
    "                        units=True,\n",
    "                    ),\n",
    "                    boxed_match_priority=0,\n",
    "                    try_extract_without_anchor=False,\n",
    "                )\n",
    "            ],\n",
    "            extraction_mode=\"first_match\",\n",
    "        )\n",
    "\n",
    "        if len(answer_parsed) > 0 and not isinstance(answer_parsed[0], str):\n",
    "            answer_val = float(answer_parsed[0])\n",
    "    if answer_val is not None:\n",
    "        mae = np.median(np.abs(float(gold_val) - answer_val))\n",
    "        return mae\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def get_tokenizer(\n",
    "    model_args: ModelConfig, training_args, auto_set_chat_template: bool = True\n",
    ") -> PreTrainedTokenizer:\n",
    "    \"\"\"Get the tokenizer for the model.\"\"\"\n",
    "    # https://github.com/huggingface/open-r1/blob/eeca246b078457bc0f69ba2e8297b799df0e2bda/src/open_r1/utils/model_utils.py#L11\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        model_args.model_name_or_path,\n",
    "        revision=model_args.model_revision,\n",
    "        trust_remote_code=False, # model_args.trust_remote_code\n",
    "    )\n",
    "\n",
    "    if training_args.chat_template is not None:\n",
    "        tokenizer.chat_template = training_args.chat_template\n",
    "    elif auto_set_chat_template and tokenizer.get_chat_template() is None:\n",
    "        tokenizer.chat_template = DEFAULT_CHAT_TEMPLATE\n",
    "    return tokenizer\n",
    "\n",
    "def get_model(model_name, attn_implementation=\"flash_attention_2\"):\n",
    "    # Initialize base model\n",
    "    if attn_implementation is not None:\n",
    "        kwargs_dict = {\"attn_implementation\": attn_implementation}\n",
    "    else:\n",
    "        kwargs_dict = {}\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        trust_remote_code=True,\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        device_map=\"cuda:0\", #TODO: how it affects the ddp https://huggingface.co/openai/whisper-large-v3/discussions/63\n",
    "        low_cpu_mem_usage=True, #TODO: ??\n",
    "        # use_safetensors=True, #TODO: ??\n",
    "        **kwargs_dict\n",
    "    )\n",
    "\n",
    "    print(f\"Model parameters: {model.num_parameters():,}\")\n",
    "\n",
    "    # Check CUDA availability\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    # device = \"cpu\"\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # Move model to the appropriate device\n",
    "    model.to(device)\n",
    "\n",
    "    return model\n",
    "\n",
    "def test_trained_model_inference(sample: str, model, tokenizer):\n",
    "    \"\"\"Test inference with the loaded trained model and tokenizer.\"\"\"\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    with torch.no_grad():\n",
    "        # Apply chat template using our tokenizer\n",
    "        text = tokenizer.apply_chat_template(\n",
    "            sample,\n",
    "            tokenize=False,\n",
    "            add_generation_prompt=True\n",
    "        )\n",
    "\n",
    "        # Tokenize the input text\n",
    "        inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "\n",
    "        # Generate output using our *trained_model*\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=1024, # Maybe generate a bit longer now\n",
    "            do_sample=False,\n",
    "            temperature=0.0 #0.7\n",
    "        )\n",
    "\n",
    "        # Decode the generated tokens back to text\n",
    "        response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return response\n",
    "\n",
    "def evaluate(SYSTEM_PROMPT, problem_template, model_name, rules=\"\"):\n",
    "    system_prompt_ = SYSTEM_PROMPT(\"LogD\", rules)\n",
    "    problem_template_ = problem_template(\"LogD\", \"<smiles>\")\n",
    "    system_prompt_hash = hashlib.blake2b(system_prompt_.encode('utf-8'), digest_size=4).hexdigest()\n",
    "    problem_template_hash = hashlib.blake2b(problem_template_.encode('utf-8'), digest_size=4).hexdigest()\n",
    "    \n",
    "    dir_name = f\"./benchmark/{model_name}/{system_prompt_hash}_{problem_template_hash}\"\n",
    "    Path(dir_name).mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    prompt_pth = f\"{dir_name}/prompt.json\"\n",
    "\n",
    "    if not Path(prompt_pth).exists():\n",
    "        with open(prompt_pth, \"w\") as f:\n",
    "            json.dump({\n",
    "                \"system_prompt\": system_prompt_,\n",
    "                \"rules\": rules,\n",
    "                \"problem_template\": problem_template_\n",
    "            }, f, indent=4)\n",
    "\n",
    "    dataset = get_dataset(params=[\"LogD\"], subset_train=50, system_prompt_fn=SYSTEM_PROMPT, prompt_template_fn=problem_template)[\"validation\"]\n",
    "    model = get_model(model_name, attn_implementation=\"flash_attention_2\")\n",
    "    model.eval()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    model_args_i = Munch.fromDict({\n",
    "            \"model_name_or_path\": model_name,\n",
    "            \"model_revision\": \"main\",\n",
    "            \"trust_remote_code\": False # TODO: everyboudy sets to True and default is True\n",
    "            })\n",
    "    training_args_i = Munch.fromDict({\"chat_template\": \"{% if not add_generation_prompt is defined %}{% set add_generation_prompt = false %}{% endif %}{% set ns = namespace(is_first=false, is_tool=false, is_output_first=true, system_prompt='') %}{%- for message in messages %}{%- if message['role'] == 'system' %}{% set ns.system_prompt = message['content'] %}{%- endif %}{%- endfor %}{{bos_token}}{{ns.system_prompt}}{%- for message in messages %}{%- if message['role'] == 'user' %}{%- set ns.is_tool = false -%}{{'<｜User｜>' + message['content']}}{%- endif %}{%- if message['role'] == 'assistant' and message['content'] is none %}{%- set ns.is_tool = false -%}{%- for tool in message['tool_calls']%}{%- if not ns.is_first %}{{'<｜Assistant｜><｜tool▁calls▁begin｜><｜tool▁call▁begin｜>' + tool['type'] + '<｜tool▁sep｜>' + tool['function']['name'] + '\\\\n' + '```json' + '\\\\n' + tool['function']['arguments'] + '\\\\n' + '```' + '<｜tool▁call▁end｜>'}}{%- set ns.is_first = true -%}{%- else %}{{'\\\\n' + '<｜tool▁call▁begin｜>' + tool['type'] + '<｜tool▁sep｜>' + tool['function']['name'] + '\\\\n' + '```json' + '\\\\n' + tool['function']['arguments'] + '\\\\n' + '```' + '<｜tool▁call▁end｜>'}}{{'<｜tool▁calls▁end｜><｜end▁of▁sentence｜>'}}{%- endif %}{%- endfor %}{%- endif %}{%- if message['role'] == 'assistant' and message['content'] is not none %}{%- if ns.is_tool %}{{'<｜tool▁outputs▁end｜>' + message['content'] + '<｜end▁of▁sentence｜>'}}{%- set ns.is_tool = false -%}{%- else %}{% set content = message['content'] %}{{'<｜Assistant｜>' + content + '<｜end▁of▁sentence｜>'}}{%- endif %}{%- endif %}{%- if message['role'] == 'tool' %}{%- set ns.is_tool = true -%}{%- if ns.is_output_first %}{{'<｜tool▁outputs▁begin｜><｜tool▁output▁begin｜>' + message['content'] + '<｜tool▁output▁end｜>'}}{%- set ns.is_output_first = false %}{%- else %}{{'\\\\n<｜tool▁output▁begin｜>' + message['content'] + '<｜tool▁output▁end｜>'}}{%- endif %}{%- endif %}{%- endfor -%}{% if ns.is_tool %}{{'<｜tool▁outputs▁end｜>'}}{% endif %}{% if add_generation_prompt and not ns.is_tool %}{{'<｜Assistant｜>'}}{% endif %}\"})\n",
    "\n",
    "    tokenizer = get_tokenizer(model_args_i, training_args_i)\n",
    "\n",
    "    maes = []\n",
    "    for batch in tqdm(dataset, total=len(dataset)):\n",
    "        response = test_trained_model_inference(batch, model, tokenizer)\n",
    "        print(batch, response)\n",
    "        mae = compute_mae_v2(response, batch[\"solution\"])\n",
    "        maes.append(mae)\n",
    "    \n",
    "    return np.mean([l for l in maes if l is not None])\n",
    "\n",
    "\n",
    "def get_dataset(params=[\"MLM\", \"HLM\", \"KSOL\", \"LogD\", \"MDR1-MDCKII\"], subset_train=None, subset_valid=None, subset_test=None, rules_prompt_name=\"rules_v4\", rewrite=False, system_prompt_fn=SYSTEM_PROMPT, prompt_template_fn=problem_template):\n",
    "    dataset = load_polaris_dataset(params=params, rules_prompt_name=rules_prompt_name, rewrite=rewrite)\n",
    "\n",
    "    print(f\"Train set size: {len(dataset['train'])}\")\n",
    "    print(f\"Test set size: {len(dataset['test'])}\")\n",
    "\n",
    "    if subset_train is not None:\n",
    "        dataset[\"train\"] = dataset[\"train\"].select(range(subset_train))\n",
    "    if subset_valid is not None:\n",
    "        dataset[\"validation\"] = dataset[\"validation\"].select(range(subset_valid))\n",
    "    if subset_test is not None:\n",
    "        dataset[\"test\"] = dataset[\"test\"].select(range(subset_test))\n",
    "\n",
    "    validate_dataset(dataset)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dct = {\"MLM\": \"is Mouse Liver Microsomal stability measured in uL/min/mg.\",\n",
    "    \"HLM\": \"is Human Liver Microsomal stability measured in uL/min/mg.\", \n",
    "    \"KSOL\": \"is Solubility measured in uM.\",\n",
    "    \"LogD\": \"is Lipophilicity, like solubility but then in fatty tissue. LogD is a measure of a molecule's lipophilicity.\",\n",
    "    \"MDR1-MDCKII\": \"is Cell permeation measured in 10^-6 cm/s.\"\n",
    "    }\n",
    "\n",
    "SYSTEM_PROMPT_1 = lambda x, rules_prompt_name: f\"\"\"You are an experienced Chemist that provides well-reasoned and detailed responses and excells at extimating ADME properties of molecules, especially {x}. {x} {dct[x]}\n",
    "User asks you to estimate and predict {x} for a small molecule, you first think about the reasoning process as an internal monologue and then provide the user with the answer. Respond in the following format: <think>\\n...\\n</think>\\n<answer>\\n...\\n</answer>. Inside <answer>\\n...\\n</answer> put the final {x} prediction in the following format: \\\\boxed{{RESULT}}, where RESULT is just the final number in float or expression that solves the problem.\n",
    "\"\"\"\n",
    "\n",
    "problem_template = lambda v_name, k: f\"What is the numerical value of {v_name} of the '{k}'?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 221/221 [00:00<00:00, 5797.95 examples/s]\n",
      "Map: 100%|██████████| 49/49 [00:00<00:00, 4930.45 examples/s]\n",
      "Map: 100%|██████████| 52/52 [00:00<00:00, 4942.86 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 221\n",
      "Test set size: 49\n",
      "\n",
      "Validating train split:\n",
      "✓ All required fields present\n",
      "✓ Prompt format is correct\n",
      "\n",
      "Validating test split:\n",
      "✓ All required fields present\n",
      "✓ Prompt format is correct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters: 7,615,616,512\n",
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/52 [00:00<?, ?it/s]/home/alisavin/AgenticADMET/openr1/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:629: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/home/alisavin/AgenticADMET/openr1/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:634: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
      "  2%|▏         | 1/52 [00:39<33:21, 39.24s/it]Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'solution': 2.9, 'problem': \"What is the numerical value of LogD of the 'CC(C)(C)[C@H](NC1=NC=NC2=C1C=C(C1=CN(CC(N)=O)N=C1)N2)C1=CC=C2OCCOC2=N1 |o1:4|'?\", 'property': 'LogD', 'smiles': 'CC(C)(C)[C@H](NC1=NC=NC2=C1C=C(C1=CN(CC(N)=O)N=C1)N2)C1=CC=C2OCCOC2=N1 |o1:4|', 'ground_truth': 2.9, 'prompt': [{'content': \"You are an experienced Chemist that provides well-reasoned and detailed responses and excells at extimating ADME properties of molecules, especially LogD. LogD is Lipophilicity, like solubility but then in fatty tissue. LogD is a measure of a molecule's lipophilicity.\\nUser asks you to estimate and predict LogD for a small molecule, you first think about the reasoning process as an internal monologue and then provide the user with the answer. Respond in the following format: <think>\\n...\\n</think>\\n<answer>\\n...\\n</answer>. Inside <answer>\\n...\\n</answer> put the final LogD prediction in the following format: \\\\boxed{RESULT}, where RESULT is just the final number in float or expression that solves the problem.\\nHere are some rules that might help you to predict LogD:\\n{'LogD': '\\\\n- If the SMILES contains “CC(C)(C)” (a tert‐butyl group) attached at a chiral center (e.g. “CC(C)(C)C@H”), then expect an increase in LogD by roughly 1–1.5 units compared to a similar scaffold lacking this group.\\\\n- If the molecule shows a fragment like “NC1=NC=NC2=C1C=C(C1=CN(…))N2” appended to a tert‐butyl bearing center, then LogD values typically fall in the ~3.1–3.2 range.\\\\n- If a structure features two or more fused aromatic rings (e.g. “C1=CC=C2…C2=C1”), then the overall lipophilicity is enhanced and LogD tends to be above 2.5.\\\\n- If an aromatic ring is directly substituted with halogens such as “Cl” or “F” (for instance, “C1=CC(Cl)=CC=C1”), then expect a boost in LogD by about 0.5 units relative to an unsubstituted ring.\\\\n- If multiple halogens are present on separate aromatic rings (e.g. both “Cl” and “F” on different rings), then the cumulative effect can raise LogD by around 1.0 unit or more.\\\\n- If the SMILES shows an “OCCOC” or “OCCOC2=” fragment (typical of ether linkers between aromatic rings), then these oxygenated linkers slightly reduce lipophilicity—often lowering LogD by 0.2–0.5 units compared to a direct aryl–aryl bond.\\\\n- If a sulfonyl fragment appears (i.e. “S(=O)(=O)”), especially appended to an aromatic or aliphatic segment, then LogD is reduced by roughly 0.5–1.0 units because of the high polarity of sulfonyl groups.\\\\n- If the structure contains an amide linkage (–C(=O)N–) not shielded by bulky groups, then expect a drop in LogD on the order of 0.3–0.7 units relative to analogous non‐amide linkers.\\\\n- If a free carboxylic acid group (“C(=O)O”) is present and not sterically hindered, then the compound tends to have a LogD that is 1–2 units lower than a similar ester or amide analogue.\\\\n- If a primary or secondary amine appears (e.g. “NC” or “N(C)C”) that is likely protonated at pH 7.4, then the molecule’s LogD will be lowered by approximately 1 unit relative to a neutral analogue.\\\\n- If a quaternary ammonium group (e.g. “N+(CH3)3”) is evident, then expect a dramatic drop in LogD – often resulting in near‐zero or negative values.\\\\n- If a heterocyclic aromatic ring contains a non‐protonated nitrogen (e.g. pyridine-like fragments such as “c1ccncc1”), then this feature tends to reduce LogD by 0.2–0.5 units relative to pure carbocyclic aromatics.\\\\n- If an extended conjugated system is present (for example, several aromatic rings linked by conjugated bonds), then the molecule often exhibits LogD values above 3 due to the cumulative hydrophobic surface.\\\\n- If polar groups (e.g. –OH, –NH2, –C(=O)O) are positioned so that intramolecular hydrogen bonding is likely, then their effective polarity is “masked” and LogD may be higher than predicted by counting polar groups alone.\\\\n- If a nitro group (–NO2) is present, then its strong electron‐withdrawing nature usually reduces LogD by about 1 unit or more.\\\\n- If an aromatic ether (Ar–O–Ar) is present rather than an aliphatic ether (R–O–R), then the effect on LogD is less pronounced—predict a LogD that is ~0.2–0.3 units higher than for an aliphatic ether analogue.\\\\n- If a carbonyl (C=O) is directly attached to an aromatic ring (as in an aromatic ketone), then expect a modest LogD reduction (around 0.3 units) versus a fully hydrocarbon substituted ring.\\\\n- If an alkyne is present in an aliphatic chain (e.g. “C#C” in “C#CCCC…”), then its low polarity means it contributes little to water solubility, keeping LogD relatively high.\\\\n- If the SMILES indicates a branched alkyl chain (such as an isopropyl group “CC(C)”) rather than a straight chain, then the branching typically increases LogD by enhancing hydrophobicity.\\\\n- If the structure contains multiple amide bonds in a row (e.g. a di- or tri-amide linker), then their combined polar effect can lower LogD by up to 1.5–2 units unless balanced by large lipophilic groups.\\\\n- If the molecule features a rigid bicyclic or polycyclic aromatic system (e.g. fused rings like “C1=CC2=CC=CC=C2C=C1”), then expect LogD values in the upper range (typically 2.5–4.0) because of the efficient stacking in lipophilic environments.\\\\n- If a spirocyclic motif is present, then the compact, three-dimensional arrangement often “hides” polar groups, leading to an increase in LogD by around 0.5 units relative to a more extended analogue.\\\\n- If the heterocycle is larger (e.g. a quinoline or isoquinoline instead of a pyridine), then the additional aromatic carbon atoms generally boost LogD by ~0.5–1.0 units.\\\\n- If bridging –CH2– groups are present between rings (e.g. “–CH2–” linking two aromatics), then these bridges increase hydrophobicity by reducing the effective polar surface area, raising LogD slightly.\\\\n- If the SMILES includes electron-withdrawing substituents (e.g. “CF3” or “Cl”) on an aromatic ring, then these groups reduce hydrogen-bonding capacity and typically increase LogD by about 0.3–0.7 units.\\\\n- If electron-donating groups (e.g. “OCH3”) are attached to an aromatic ring, then the increased polarity may lower LogD by ~0.2–0.5 units relative to a halogenated or unsubstituted ring.\\\\n- If a cyclic ether (e.g. a tetrahydrofuran ring represented as “C1CCOC1”) is incorporated, then its moderate polarity can reduce LogD by approximately 0.3–0.7 units compared to an all‐carbon ring of similar size.\\\\n- If the polar groups (such as amides or carboxyls) appear on the periphery of a large, lipophilic scaffold, then their impact on LogD is partially offset—resulting in LogD values that are about 0.5–1 unit higher than if the same polar groups were isolated.\\\\n- If steric hindrance is evident around a normally polar group (for example, an amide adjacent to a bulky tert‐butyl group), then the effective exposure of that polar functionality is reduced, leading to a higher LogD than predicted by polarity alone.\\\\n- If the overall structure can be roughly “fragmented” into lipophilic and hydrophilic pieces, then the net LogD is roughly additive. For example, two strongly lipophilic aromatic rings plus one polar amide might yield a predicted LogD in the range of 2.5–3.0, whereas replacing the amide with a carboxylic acid may drop the value by 1–1.5 units.\\\\n'}\\n\", 'role': 'system'}, {'content': \"What is the numerical value of LogD of the 'CC(C)(C)[C@H](NC1=NC=NC2=C1C=C(C1=CN(CC(N)=O)N=C1)N2)C1=CC=C2OCCOC2=N1 |o1:4|'?\", 'role': 'user'}]} <｜Assistant｜>  the  222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 2/52 [01:18<32:43, 39.26s/it]Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'solution': 4.0, 'problem': \"What is the numerical value of LogD of the 'CC(C)[C@H](NC1=NC=NC2=C1C=C(C1=CN3C=NC=C3C=C1)N2)C1=CC=C2CCCS(=O)(=O)C2=C1 |&1:3|'?\", 'property': 'LogD', 'smiles': 'CC(C)[C@H](NC1=NC=NC2=C1C=C(C1=CN3C=NC=C3C=C1)N2)C1=CC=C2CCCS(=O)(=O)C2=C1 |&1:3|', 'ground_truth': 4.0, 'prompt': [{'content': \"You are an experienced Chemist that provides well-reasoned and detailed responses and excells at extimating ADME properties of molecules, especially LogD. LogD is Lipophilicity, like solubility but then in fatty tissue. LogD is a measure of a molecule's lipophilicity.\\nUser asks you to estimate and predict LogD for a small molecule, you first think about the reasoning process as an internal monologue and then provide the user with the answer. Respond in the following format: <think>\\n...\\n</think>\\n<answer>\\n...\\n</answer>. Inside <answer>\\n...\\n</answer> put the final LogD prediction in the following format: \\\\boxed{RESULT}, where RESULT is just the final number in float or expression that solves the problem.\\nHere are some rules that might help you to predict LogD:\\n{'LogD': '\\\\n- If the SMILES contains “CC(C)(C)” (a tert‐butyl group) attached at a chiral center (e.g. “CC(C)(C)C@H”), then expect an increase in LogD by roughly 1–1.5 units compared to a similar scaffold lacking this group.\\\\n- If the molecule shows a fragment like “NC1=NC=NC2=C1C=C(C1=CN(…))N2” appended to a tert‐butyl bearing center, then LogD values typically fall in the ~3.1–3.2 range.\\\\n- If a structure features two or more fused aromatic rings (e.g. “C1=CC=C2…C2=C1”), then the overall lipophilicity is enhanced and LogD tends to be above 2.5.\\\\n- If an aromatic ring is directly substituted with halogens such as “Cl” or “F” (for instance, “C1=CC(Cl)=CC=C1”), then expect a boost in LogD by about 0.5 units relative to an unsubstituted ring.\\\\n- If multiple halogens are present on separate aromatic rings (e.g. both “Cl” and “F” on different rings), then the cumulative effect can raise LogD by around 1.0 unit or more.\\\\n- If the SMILES shows an “OCCOC” or “OCCOC2=” fragment (typical of ether linkers between aromatic rings), then these oxygenated linkers slightly reduce lipophilicity—often lowering LogD by 0.2–0.5 units compared to a direct aryl–aryl bond.\\\\n- If a sulfonyl fragment appears (i.e. “S(=O)(=O)”), especially appended to an aromatic or aliphatic segment, then LogD is reduced by roughly 0.5–1.0 units because of the high polarity of sulfonyl groups.\\\\n- If the structure contains an amide linkage (–C(=O)N–) not shielded by bulky groups, then expect a drop in LogD on the order of 0.3–0.7 units relative to analogous non‐amide linkers.\\\\n- If a free carboxylic acid group (“C(=O)O”) is present and not sterically hindered, then the compound tends to have a LogD that is 1–2 units lower than a similar ester or amide analogue.\\\\n- If a primary or secondary amine appears (e.g. “NC” or “N(C)C”) that is likely protonated at pH 7.4, then the molecule’s LogD will be lowered by approximately 1 unit relative to a neutral analogue.\\\\n- If a quaternary ammonium group (e.g. “N+(CH3)3”) is evident, then expect a dramatic drop in LogD – often resulting in near‐zero or negative values.\\\\n- If a heterocyclic aromatic ring contains a non‐protonated nitrogen (e.g. pyridine-like fragments such as “c1ccncc1”), then this feature tends to reduce LogD by 0.2–0.5 units relative to pure carbocyclic aromatics.\\\\n- If an extended conjugated system is present (for example, several aromatic rings linked by conjugated bonds), then the molecule often exhibits LogD values above 3 due to the cumulative hydrophobic surface.\\\\n- If polar groups (e.g. –OH, –NH2, –C(=O)O) are positioned so that intramolecular hydrogen bonding is likely, then their effective polarity is “masked” and LogD may be higher than predicted by counting polar groups alone.\\\\n- If a nitro group (–NO2) is present, then its strong electron‐withdrawing nature usually reduces LogD by about 1 unit or more.\\\\n- If an aromatic ether (Ar–O–Ar) is present rather than an aliphatic ether (R–O–R), then the effect on LogD is less pronounced—predict a LogD that is ~0.2–0.3 units higher than for an aliphatic ether analogue.\\\\n- If a carbonyl (C=O) is directly attached to an aromatic ring (as in an aromatic ketone), then expect a modest LogD reduction (around 0.3 units) versus a fully hydrocarbon substituted ring.\\\\n- If an alkyne is present in an aliphatic chain (e.g. “C#C” in “C#CCCC…”), then its low polarity means it contributes little to water solubility, keeping LogD relatively high.\\\\n- If the SMILES indicates a branched alkyl chain (such as an isopropyl group “CC(C)”) rather than a straight chain, then the branching typically increases LogD by enhancing hydrophobicity.\\\\n- If the structure contains multiple amide bonds in a row (e.g. a di- or tri-amide linker), then their combined polar effect can lower LogD by up to 1.5–2 units unless balanced by large lipophilic groups.\\\\n- If the molecule features a rigid bicyclic or polycyclic aromatic system (e.g. fused rings like “C1=CC2=CC=CC=C2C=C1”), then expect LogD values in the upper range (typically 2.5–4.0) because of the efficient stacking in lipophilic environments.\\\\n- If a spirocyclic motif is present, then the compact, three-dimensional arrangement often “hides” polar groups, leading to an increase in LogD by around 0.5 units relative to a more extended analogue.\\\\n- If the heterocycle is larger (e.g. a quinoline or isoquinoline instead of a pyridine), then the additional aromatic carbon atoms generally boost LogD by ~0.5–1.0 units.\\\\n- If bridging –CH2– groups are present between rings (e.g. “–CH2–” linking two aromatics), then these bridges increase hydrophobicity by reducing the effective polar surface area, raising LogD slightly.\\\\n- If the SMILES includes electron-withdrawing substituents (e.g. “CF3” or “Cl”) on an aromatic ring, then these groups reduce hydrogen-bonding capacity and typically increase LogD by about 0.3–0.7 units.\\\\n- If electron-donating groups (e.g. “OCH3”) are attached to an aromatic ring, then the increased polarity may lower LogD by ~0.2–0.5 units relative to a halogenated or unsubstituted ring.\\\\n- If a cyclic ether (e.g. a tetrahydrofuran ring represented as “C1CCOC1”) is incorporated, then its moderate polarity can reduce LogD by approximately 0.3–0.7 units compared to an all‐carbon ring of similar size.\\\\n- If the polar groups (such as amides or carboxyls) appear on the periphery of a large, lipophilic scaffold, then their impact on LogD is partially offset—resulting in LogD values that are about 0.5–1 unit higher than if the same polar groups were isolated.\\\\n- If steric hindrance is evident around a normally polar group (for example, an amide adjacent to a bulky tert‐butyl group), then the effective exposure of that polar functionality is reduced, leading to a higher LogD than predicted by polarity alone.\\\\n- If the overall structure can be roughly “fragmented” into lipophilic and hydrophilic pieces, then the net LogD is roughly additive. For example, two strongly lipophilic aromatic rings plus one polar amide might yield a predicted LogD in the range of 2.5–3.0, whereas replacing the amide with a carboxylic acid may drop the value by 1–1.5 units.\\\\n'}\\n\", 'role': 'system'}, {'content': \"What is the numerical value of LogD of the 'CC(C)[C@H](NC1=NC=NC2=C1C=C(C1=CN3C=NC=C3C=C1)N2)C1=CC=C2CCCS(=O)(=O)C2=C1 |&1:3|'?\", 'role': 'user'}]} <｜Assistant｜>  the  222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 2/52 [01:18<32:49, 39.39s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m m \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSYSTEM_PROMPT_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproblem_template\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdeepseek-ai/DeepSeek-R1-Distill-Qwen-7B\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrules\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(m)\n",
      "Cell \u001b[0;32mIn[23], line 181\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(SYSTEM_PROMPT, problem_template, model_name, rules)\u001b[0m\n\u001b[1;32m    179\u001b[0m maes \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m tqdm(dataset, total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(dataset)):\n\u001b[0;32m--> 181\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtest_trained_model_inference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28mprint\u001b[39m(batch, response)\n\u001b[1;32m    183\u001b[0m     mae \u001b[38;5;241m=\u001b[39m compute_mae_v2(response, batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msolution\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "Cell \u001b[0;32mIn[23], line 134\u001b[0m, in \u001b[0;36mtest_trained_model_inference\u001b[0;34m(sample, model, tokenizer)\u001b[0m\n\u001b[1;32m    131\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tokenizer(text, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    133\u001b[0m \u001b[38;5;66;03m# Generate output using our *trained_model*\u001b[39;00m\n\u001b[0;32m--> 134\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Maybe generate a bit longer now\u001b[39;49;00m\n\u001b[1;32m    137\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m#0.7\u001b[39;49;00m\n\u001b[1;32m    139\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;66;03m# Decode the generated tokens back to text\u001b[39;00m\n\u001b[1;32m    142\u001b[0m response \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode(outputs[\u001b[38;5;241m0\u001b[39m], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/AgenticADMET/openr1/lib/python3.11/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/AgenticADMET/openr1/lib/python3.11/site-packages/transformers/generation/utils.py:2223\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   2215\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   2216\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   2217\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   2218\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   2219\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2220\u001b[0m     )\n\u001b[1;32m   2222\u001b[0m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[0;32m-> 2223\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2224\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2225\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2226\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2228\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2229\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2230\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2231\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2233\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[1;32m   2234\u001b[0m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[1;32m   2235\u001b[0m     beam_scorer \u001b[38;5;241m=\u001b[39m BeamSearchScorer(\n\u001b[1;32m   2236\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   2237\u001b[0m         num_beams\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2242\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mmax_length,\n\u001b[1;32m   2243\u001b[0m     )\n",
      "File \u001b[0;32m~/AgenticADMET/openr1/lib/python3.11/site-packages/transformers/generation/utils.py:3214\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   3212\u001b[0m     is_prefill \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   3213\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3214\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   3216\u001b[0m \u001b[38;5;66;03m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[39;00m\n\u001b[1;32m   3217\u001b[0m model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_model_kwargs_for_generation(\n\u001b[1;32m   3218\u001b[0m     outputs,\n\u001b[1;32m   3219\u001b[0m     model_kwargs,\n\u001b[1;32m   3220\u001b[0m     is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   3221\u001b[0m )\n",
      "File \u001b[0;32m~/AgenticADMET/openr1/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/AgenticADMET/openr1/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/AgenticADMET/openr1/lib/python3.11/site-packages/transformers/utils/deprecation.py:172\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action\u001b[38;5;241m.\u001b[39mNOTIFY, Action\u001b[38;5;241m.\u001b[39mNOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[1;32m    170\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/AgenticADMET/openr1/lib/python3.11/site-packages/transformers/models/qwen2/modeling_qwen2.py:856\u001b[0m, in \u001b[0;36mQwen2ForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, logits_to_keep, **kwargs)\u001b[0m\n\u001b[1;32m    853\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m    855\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m--> 856\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    866\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    867\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    870\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    871\u001b[0m \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n",
      "File \u001b[0;32m~/AgenticADMET/openr1/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/AgenticADMET/openr1/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/AgenticADMET/openr1/lib/python3.11/site-packages/transformers/models/qwen2/modeling_qwen2.py:579\u001b[0m, in \u001b[0;36mQwen2Model.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, **flash_attn_kwargs)\u001b[0m\n\u001b[1;32m    567\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    568\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    569\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    576\u001b[0m         position_embeddings,\n\u001b[1;32m    577\u001b[0m     )\n\u001b[1;32m    578\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 579\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    580\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    581\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    584\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    585\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    587\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    588\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mflash_attn_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    589\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    593\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "File \u001b[0;32m~/AgenticADMET/openr1/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/AgenticADMET/openr1/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/AgenticADMET/openr1/lib/python3.11/site-packages/transformers/models/qwen2/modeling_qwen2.py:276\u001b[0m, in \u001b[0;36mQwen2DecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    274\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[1;32m    275\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_attention_layernorm(hidden_states)\n\u001b[0;32m--> 276\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    277\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[1;32m    279\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (hidden_states,)\n",
      "File \u001b[0;32m~/AgenticADMET/openr1/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/AgenticADMET/openr1/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/AgenticADMET/openr1/lib/python3.11/site-packages/transformers/models/qwen2/modeling_qwen2.py:57\u001b[0m, in \u001b[0;36mQwen2MLP.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 57\u001b[0m     down_proj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdown_proj(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact_fn(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgate_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mup_proj(x))\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m down_proj\n",
      "File \u001b[0;32m~/AgenticADMET/openr1/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/AgenticADMET/openr1/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/AgenticADMET/openr1/lib/python3.11/site-packages/torch/nn/modules/linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "m = evaluate(SYSTEM_PROMPT_1, problem_template, \"deepseek-ai/DeepSeek-R1-Distill-Qwen-7B\", rules=\"\")\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 221/221 [00:00<00:00, 5918.56 examples/s]\n",
      "Map: 100%|██████████| 49/49 [00:00<00:00, 4842.96 examples/s]\n",
      "Map: 100%|██████████| 52/52 [00:00<00:00, 4929.57 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 221\n",
      "Test set size: 49\n",
      "\n",
      "Validating train split:\n",
      "✓ All required fields present\n",
      "✓ Prompt format is correct\n",
      "\n",
      "Validating test split:\n",
      "✓ All required fields present\n",
      "✓ Prompt format is correct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = get_dataset(params=[\"LogD\"], subset_train=50, system_prompt_fn=SYSTEM_PROMPT, prompt_template_fn=problem_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openr1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
