{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alisavin/AgenticADMET/openr1/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 03-02 00:05:16 __init__.py:190] Automatically detected platform cuda.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-02 00:05:17,175\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from dataset import load_polaris_dataset, validate_dataset\n",
    "from train import get_dataset\n",
    "import numpy as np\n",
    "from latex2sympy2_extended import NormalizationConfig\n",
    "from math_verify import LatexExtractionConfig, parse\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    TrainingArguments,\n",
    "    PreTrainedTokenizer\n",
    ")\n",
    "import torch\n",
    "from peft import PeftModel\n",
    "from peft import prepare_model_for_kbit_training\n",
    "from trl import ModelConfig\n",
    "from munch import Munch\n",
    "import json\n",
    "from pathlib import Path\n",
    "from functools import partial\n",
    "import hashlib\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "from train import GRPOTrainer2\n",
    "import os\n",
    "from trl import (\n",
    "    GRPOConfig, \n",
    "    GRPOTrainer,\n",
    "    get_peft_config\n",
    ")\n",
    "from dataclasses import field, dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_CHAT_TEMPLATE = \"{% for message in messages %}\\n{% if message['role'] == 'user' %}\\n{{ '<|user|>\\n' + message['content'] + eos_token }}\\n{% elif message['role'] == 'system' %}\\n{{ '<|system|>\\n' + message['content'] + eos_token }}\\n{% elif message['role'] == 'assistant' %}\\n{{ '<|assistant|>\\n'  + message['content'] + eos_token }}\\n{% endif %}\\n{% if loop.last and add_generation_prompt %}\\n{{ '<|assistant|>' }}\\n{% endif %}\\n{% endfor %}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mae(contents, smiles, solutions):\n",
    "    if solutions is None:\n",
    "        return [0.5] * len(contents) # Return neutral reward if no solution\n",
    "    smiles2conts = defaultdict(list)\n",
    "    for content, gold_val, smiles_i in zip(contents, solutions, smiles):\n",
    "        answer_val = None\n",
    "        if gold_val is not None:\n",
    "            answer_parsed = parse(\n",
    "                content,\n",
    "                extraction_config=[\n",
    "                    LatexExtractionConfig(\n",
    "                        normalization_config=NormalizationConfig(\n",
    "                            nits=False,\n",
    "                            malformed_operators=False,\n",
    "                            basic_latex=True,\n",
    "                            equations=True,\n",
    "                            boxed=\"all\",\n",
    "                            units=True,\n",
    "                        ),\n",
    "                        boxed_match_priority=0,\n",
    "                        try_extract_without_anchor=False,\n",
    "                    )\n",
    "                ],\n",
    "                extraction_mode=\"first_match\",\n",
    "            )\n",
    "\n",
    "            if len(answer_parsed) > 0 and not isinstance(answer_parsed[0], str):\n",
    "                answer_val = float(answer_parsed[0])\n",
    "        \n",
    "        smiles_hash = hashlib.blake2b(smiles_i.encode('utf-8'), digest_size=4).hexdigest()\n",
    "        smiles2conts[smiles_hash].append({\n",
    "                       \"answer_val\": answer_val\n",
    "                       }) \n",
    "    median_maes = []\n",
    "    for k, v in smiles2conts.items():\n",
    "        answers_g = [v_i[\"answer_val\"] for v_i in v]\n",
    "        answers_g = [float(v_i) for v_i in answers_g if v_i is not None]\n",
    "        answer_median = np.median(answers_g)\n",
    "        mae_median = np.median(np.abs(float(v[0][\"gold_val\"]) - answer_median))\n",
    "        median_maes.append(mae_median)\n",
    "    return median_maes\n",
    "\n",
    "def get_tokenizer(\n",
    "    model_args: ModelConfig, training_args, auto_set_chat_template: bool = True\n",
    ") -> PreTrainedTokenizer:\n",
    "    \"\"\"Get the tokenizer for the model.\"\"\"\n",
    "    # https://github.com/huggingface/open-r1/blob/eeca246b078457bc0f69ba2e8297b799df0e2bda/src/open_r1/utils/model_utils.py#L11\n",
    "    print(\"loading tokenizer\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        model_args.model_name_or_path,\n",
    "        revision=model_args.model_revision,\n",
    "        trust_remote_code=False, # model_args.trust_remote_code\n",
    "    )\n",
    "    print(\"tokenizer loaded\")\n",
    "\n",
    "    if training_args.chat_template is not None:\n",
    "        tokenizer.chat_template = training_args.chat_template\n",
    "    elif auto_set_chat_template and tokenizer.get_chat_template() is None:\n",
    "        tokenizer.chat_template = DEFAULT_CHAT_TEMPLATE\n",
    "    print(\"chat template\")\n",
    "    # if processing_class is None:\n",
    "    #     processing_class = AutoTokenizer.from_pretrained(model.config._name_or_path, padding_side=\"left\")\n",
    "    return tokenizer\n",
    "\n",
    "def get_model(model_name, attn_implementation=\"flash_attention_2\"):\n",
    "    # Initialize base model\n",
    "    if attn_implementation is not None:\n",
    "        kwargs_dict = {\"attn_implementation\": attn_implementation}\n",
    "    else:\n",
    "        kwargs_dict = {}\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        trust_remote_code=True,\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        device_map=\"cuda:0\", #TODO: how it affects the ddp https://huggingface.co/openai/whisper-large-v3/discussions/63\n",
    "        low_cpu_mem_usage=True, #TODO: ??\n",
    "        # use_safetensors=True, #TODO: ??\n",
    "        **kwargs_dict\n",
    "    )\n",
    "\n",
    "    print(f\"Model parameters: {model.num_parameters():,}\")\n",
    "\n",
    "    # Check CUDA availability\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    # device = \"cpu\"\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # Move model to the appropriate device\n",
    "    model.to(device)\n",
    "\n",
    "    return model\n",
    "\n",
    "def get_reward_functions(script_args, model_name):\n",
    "    \"\"\"\n",
    "    Returns a list of reward functions based on the script arguments.\n",
    "    \"\"\"\n",
    "    reward_funcs_list = []\n",
    "\n",
    "    fnc = partial(compute_mae, model_name=model_name)\n",
    "    fnc.__name__ = compute_mae.__name__\n",
    "    reward_funcs_registry = {\n",
    "        \"mae\": fnc,  # Assuming accuracy_reward is defined in previous steps\n",
    "    }\n",
    "\n",
    "    for func_name in script_args.reward_funcs:\n",
    "        if func_name not in reward_funcs_registry:\n",
    "            raise ValueError(f\"Reward function '{func_name}' not found in registry.\")\n",
    "        reward_funcs_list.append(reward_funcs_registry[func_name])\n",
    "\n",
    "    return reward_funcs_list\n",
    "\n",
    "@dataclass\n",
    "class GRPOScriptArguments:\n",
    "    \"\"\"\n",
    "    Script arguments for GRPO training, specifically related to reward functions.\n",
    "    \"\"\"\n",
    "\n",
    "    reward_funcs: list[str] = field(\n",
    "        default_factory=lambda: [\"mae\"], \n",
    "        metadata={\n",
    "            \"help\": \"List of reward functions. Possible values: 'accuracy', 'format', 'reasoning_steps', 'repetition_penalty'\"        },\n",
    "    )\n",
    "\n",
    "    repetition_n_grams: int = field(\n",
    "        default=3,\n",
    "        metadata={\"help\": \"Number of n-grams for repetition penalty reward\"},\n",
    "    )\n",
    "    repetition_max_penalty: float = field(\n",
    "        default=-0.1,\n",
    "        metadata={\"help\": \"Maximum (negative) penalty for for repetition penalty reward\"},\n",
    "    )\n",
    "\n",
    "def test_trained_model_inference(sample: str):\n",
    "    \"\"\"Test inference with the loaded trained model and tokenizer.\"\"\"\n",
    "\n",
    "    # Apply chat template using our tokenizer\n",
    "    text = tokenizer.apply_chat_template(\n",
    "        sample,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "\n",
    "    # Tokenize the input text\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    # Generate output using our *trained_model*\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=1024, # Maybe generate a bit longer now\n",
    "        do_sample=False,\n",
    "        temperature=0.0 #0.7\n",
    "    )\n",
    "\n",
    "    # Decode the generated tokens back to text\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return response\n",
    "\n",
    "def evaluate(dataset, model_name):\n",
    "    responses = []\n",
    "    solution = []\n",
    "    smiles = []\n",
    "    for batch in tqdm(dataset, total=len(dataset)):\n",
    "        response = test_trained_model_inference(batch)\n",
    "        responses.append(response)\n",
    "        solution.append(batch[\"solution\"])\n",
    "        smiles.append(batch[\"smiles\"])\n",
    "\n",
    "    print(\"compute mae\")\n",
    "    mae = compute_mae_v2(responses, smiles, solution, model_name=model_name)\n",
    "    \n",
    "    return mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 221/221 [00:00<00:00, 12781.69 examples/s]\n",
      "Map: 100%|██████████| 49/49 [00:00<00:00, 7507.89 examples/s]\n",
      "Map: 100%|██████████| 52/52 [00:00<00:00, 7723.50 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 221\n",
      "Test set size: 49\n",
      "\n",
      "Validating train split:\n",
      "✓ All required fields present\n",
      "✓ Prompt format is correct\n",
      "\n",
      "Validating test split:\n",
      "✓ All required fields present\n",
      "✓ Prompt format is correct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = get_dataset(params=[\"LogD\"], subset_train=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters: 7,615,616,512\n",
      "Using device: cuda\n",
      "loading tokenizer\n",
      "tokenizer loaded\n",
      "chat template\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-7B\"\n",
    "\n",
    "model = get_model(MODEL_NAME, attn_implementation=\"flash_attention_2\")\n",
    "\n",
    "model = PeftModel.from_pretrained(model, \"/home/alisavin/AgenticADMET/outputs/2025-02-26/22-18-57/checkpoint-60/\")\n",
    "model.eval()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "model_args_i = Munch.fromDict({\n",
    "        \"model_name_or_path\": MODEL_NAME,\n",
    "        \"model_revision\": \"main\",\n",
    "        \"trust_remote_code\": False # TODO: everyboudy sets to True and default is True\n",
    "        })\n",
    "training_args_i = Munch.fromDict({\"chat_template\": \"{% if not add_generation_prompt is defined %}{% set add_generation_prompt = false %}{% endif %}{% set ns = namespace(is_first=false, is_tool=false, is_output_first=true, system_prompt='') %}{%- for message in messages %}{%- if message['role'] == 'system' %}{% set ns.system_prompt = message['content'] %}{%- endif %}{%- endfor %}{{bos_token}}{{ns.system_prompt}}{%- for message in messages %}{%- if message['role'] == 'user' %}{%- set ns.is_tool = false -%}{{'<｜User｜>' + message['content']}}{%- endif %}{%- if message['role'] == 'assistant' and message['content'] is none %}{%- set ns.is_tool = false -%}{%- for tool in message['tool_calls']%}{%- if not ns.is_first %}{{'<｜Assistant｜><｜tool▁calls▁begin｜><｜tool▁call▁begin｜>' + tool['type'] + '<｜tool▁sep｜>' + tool['function']['name'] + '\\\\n' + '```json' + '\\\\n' + tool['function']['arguments'] + '\\\\n' + '```' + '<｜tool▁call▁end｜>'}}{%- set ns.is_first = true -%}{%- else %}{{'\\\\n' + '<｜tool▁call▁begin｜>' + tool['type'] + '<｜tool▁sep｜>' + tool['function']['name'] + '\\\\n' + '```json' + '\\\\n' + tool['function']['arguments'] + '\\\\n' + '```' + '<｜tool▁call▁end｜>'}}{{'<｜tool▁calls▁end｜><｜end▁of▁sentence｜>'}}{%- endif %}{%- endfor %}{%- endif %}{%- if message['role'] == 'assistant' and message['content'] is not none %}{%- if ns.is_tool %}{{'<｜tool▁outputs▁end｜>' + message['content'] + '<｜end▁of▁sentence｜>'}}{%- set ns.is_tool = false -%}{%- else %}{% set content = message['content'] %}{{'<｜Assistant｜>' + content + '<｜end▁of▁sentence｜>'}}{%- endif %}{%- endif %}{%- if message['role'] == 'tool' %}{%- set ns.is_tool = true -%}{%- if ns.is_output_first %}{{'<｜tool▁outputs▁begin｜><｜tool▁output▁begin｜>' + message['content'] + '<｜tool▁output▁end｜>'}}{%- set ns.is_output_first = false %}{%- else %}{{'\\\\n<｜tool▁output▁begin｜>' + message['content'] + '<｜tool▁output▁end｜>'}}{%- endif %}{%- endif %}{%- endfor -%}{% if ns.is_tool %}{{'<｜tool▁outputs▁end｜>'}}{% endif %}{% if add_generation_prompt and not ns.is_tool %}{{'<｜Assistant｜>'}}{% endif %}\"})\n",
    "\n",
    "tokenizer = get_tokenizer(model_args_i, training_args_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/52 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
      "  2%|▏         | 1/52 [00:07<06:05,  7.17s/it]Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
      "  4%|▍         | 2/52 [00:14<05:57,  7.15s/it]Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
      "  6%|▌         | 3/52 [00:21<05:49,  7.14s/it]Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
      "  8%|▊         | 4/52 [00:28<05:42,  7.14s/it]Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
      " 10%|▉         | 5/52 [00:35<05:35,  7.15s/it]Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
      " 12%|█▏        | 6/52 [00:42<05:30,  7.19s/it]Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
      " 13%|█▎        | 7/52 [00:50<05:23,  7.20s/it]Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
      " 15%|█▌        | 8/52 [00:57<05:17,  7.21s/it]Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
      " 17%|█▋        | 9/52 [01:04<05:13,  7.28s/it]Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
      " 19%|█▉        | 10/52 [01:12<05:05,  7.27s/it]Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
      " 21%|██        | 11/52 [01:19<04:58,  7.29s/it]Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
      " 23%|██▎       | 12/52 [01:26<04:51,  7.28s/it]Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
      " 25%|██▌       | 13/52 [01:33<04:43,  7.26s/it]Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
      " 27%|██▋       | 14/52 [01:41<04:35,  7.25s/it]Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
      " 29%|██▉       | 15/52 [01:48<04:28,  7.25s/it]Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
      " 31%|███       | 16/52 [01:55<04:20,  7.23s/it]Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
      " 33%|███▎      | 17/52 [02:02<04:12,  7.21s/it]Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
      " 35%|███▍      | 18/52 [02:09<04:04,  7.19s/it]Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
      " 37%|███▋      | 19/52 [02:17<03:56,  7.17s/it]Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
      " 38%|███▊      | 20/52 [02:24<03:48,  7.16s/it]Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
      " 40%|████      | 21/52 [02:31<03:41,  7.15s/it]Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
      " 42%|████▏     | 22/52 [02:38<03:35,  7.18s/it]Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
      " 44%|████▍     | 23/52 [02:45<03:28,  7.20s/it]Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
      " 46%|████▌     | 24/52 [02:53<03:21,  7.21s/it]Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
      " 48%|████▊     | 25/52 [03:00<03:14,  7.21s/it]Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
      " 50%|█████     | 26/52 [03:07<03:07,  7.20s/it]Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
      " 52%|█████▏    | 27/52 [03:14<02:59,  7.20s/it]Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
      " 54%|█████▍    | 28/52 [03:21<02:53,  7.22s/it]Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
      " 56%|█████▌    | 29/52 [03:29<02:46,  7.23s/it]Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
      " 58%|█████▊    | 30/52 [03:36<02:38,  7.22s/it]Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
      " 60%|█████▉    | 31/52 [03:43<02:31,  7.21s/it]Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
      " 62%|██████▏   | 32/52 [03:50<02:24,  7.24s/it]Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
      " 63%|██████▎   | 33/52 [03:58<02:17,  7.26s/it]Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
      " 65%|██████▌   | 34/52 [04:05<02:11,  7.29s/it]Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
      " 67%|██████▋   | 35/52 [04:12<02:04,  7.30s/it]Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
      " 69%|██████▉   | 36/52 [04:20<01:56,  7.28s/it]Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
      " 71%|███████   | 37/52 [04:27<01:48,  7.25s/it]Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
      " 73%|███████▎  | 38/52 [04:34<01:41,  7.24s/it]Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
      " 75%|███████▌  | 39/52 [04:41<01:33,  7.23s/it]Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
      " 77%|███████▋  | 40/52 [04:48<01:26,  7.24s/it]Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
      " 79%|███████▉  | 41/52 [04:56<01:19,  7.25s/it]Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
      " 81%|████████  | 42/52 [05:03<01:12,  7.26s/it]Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
      " 83%|████████▎ | 43/52 [05:10<01:05,  7.25s/it]Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
      " 85%|████████▍ | 44/52 [05:17<00:57,  7.24s/it]Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
      " 87%|████████▋ | 45/52 [05:25<00:50,  7.22s/it]Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
      " 88%|████████▊ | 46/52 [05:32<00:43,  7.21s/it]Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
      " 90%|█████████ | 47/52 [05:39<00:36,  7.21s/it]Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
      " 92%|█████████▏| 48/52 [05:46<00:28,  7.21s/it]Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
      " 94%|█████████▍| 49/52 [05:53<00:21,  7.24s/it]Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
      " 96%|█████████▌| 50/52 [06:01<00:14,  7.24s/it]Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
      " 98%|█████████▊| 51/52 [06:08<00:07,  7.24s/it]Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
      "100%|██████████| 52/52 [06:15<00:00,  7.22s/it]\n"
     ]
    }
   ],
   "source": [
    "m = evaluate(dataset[\"validation\"], \"test/completions/init_v3_correct_format_16_v3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 221/221 [00:00<00:00, 13278.44 examples/s]\n",
      "Map: 100%|██████████| 49/49 [00:00<00:00, 7124.27 examples/s]\n",
      "Map: 100%|██████████| 52/52 [00:00<00:00, 8248.39 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 221\n",
      "Test set size: 49\n",
      "\n",
      "Validating train split:\n",
      "✓ All required fields present\n",
      "✓ Prompt format is correct\n",
      "\n",
      "Validating test split:\n",
      "✓ All required fields present\n",
      "✓ Prompt format is correct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = get_dataset(params=[\"LogD\"], rewrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_i = {}\n",
    "for b in dataset[\"train\"]:\n",
    "    dict_i[b[\"smiles\"]] = b[\"solution\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CC(C)(C)[C@H](NC1=NC=NC2=C1C=C(C1=CN(CC(N)=O)N=C1)N2)C1=CC=C2OCCOC2=C1 |o1:4|': 3.1,\n",
       " 'C[C@H]1CN(C2=CN=CC3=CC=CC=C23)C(=O)[C@@]12CN(CC1=NNC=N1)C(=O)C1=CC=C(F)C=C12': 1.3,\n",
       " 'CC(C)(C)[C@H](NC1=NC=NC2=C1C=C(C1=CN(CC(N)=O)N=C1)N2)C1=CC=C2OCCOC2=N1 |&1:4|': 2.7,\n",
       " 'CC(C)[C@H](CO)NC1=NC=NC2=C1C=CN2': 1.69,\n",
       " 'NCC1=CC=CC(NC(=O)[C@@H](NC(=O)OCC2=CC=CC=C2)C2=CC=C(OCC3=CC=CC=C3)C=C2)=C1 |a:10|': 3.2,\n",
       " 'CC(C)[C@H](NC1=NC=NC2=C1C=CN2)C1=CC=C2CCCS(=O)(=O)C2=C1 |&1:3|': 2.5,\n",
       " 'C[C@H]1CN(C2=CN=CC3=CC=CC=C23)C(=O)[C@@]12CN(CC1=NC=CN1C)C(=O)C1=CC=C(F)C=C12 |a:1,16|': 2.0,\n",
       " 'C#CCCC1=CC=C(OCCCC2=CC(C(=O)N(C)C)=NO2)C=C1': 3.5,\n",
       " 'CNC(=O)C1=CC2=C(N[C@H](C3=CC=C4CCCS(=O)(=O)C4=C3)C(C)C)N=CN=C2N1 |&1:9|': 2.4,\n",
       " 'CC1=NC2=NC=NN2C(SC2=NN=C(C)O2)=C1': 0.1,\n",
       " 'O=C(NCC(F)F)[C@H](NC1=CC=C2CNCC2=C1)C1=CC(Br)=CC2=C1NC=N2 |&1:7|': 0.4,\n",
       " 'CNC(=O)CN1C[C@@]2(C(=O)N(C3=CN=CC4=CC=CC=C34)C[C@@H]2CNC2=CC=C(Cl)N=N2)C2=CC(Cl)=CC=C2C1=O |a:7,22|': 2.1,\n",
       " 'CNC(=O)C1=CC(Cl)=CC=C1NS(=O)(=O)C1=CC=C(OC2=CC=CC=C2Cl)C=C1': 2.4,\n",
       " 'CN(C(=O)C1=CC=C2COB(O)C2=C1)[C@H]1CCN(C2CC2)C1 |&1:14|': 0.7,\n",
       " 'O=C(NC1=CC=C2CNCC2=C1)C1=CC=CC2=C1C=C(C(F)(F)F)N2': 1.5,\n",
       " 'CC(C)[C@H](NC1=NC=NC2=C1C=C(C1=CN(C)N=C1)N2)C1=CC=C2CCCS(=O)(=O)C2=C1 |&1:3|': 3.3,\n",
       " 'C1=CC=C(C2=NC3=NC=NN3C(SC3=NC=CO3)=C2)C=C1': 2.3,\n",
       " 'O=C(C1=CC=C2COB(O)C2=C1)N1CCN[C@H](C2=CC=CC=C2)C1 |&1:16|': 0.8,\n",
       " 'CC(C)(C)[C@H](NC1=NC=NC2=C1C=C(C1=CN(CC(N)=O)N=C1)N2)C1=CC=C2OCCOC2=C1 |&1:4|': 3.2,\n",
       " 'CC1=CC(C2=NOC(C(F)(F)F)=N2)=CC=C1CCOCC1=CC(C(=O)N(C)C)=NO1': 4.0,\n",
       " 'CNC(=O)CN1C[C@@]2(C(=O)N(C3=CN=CC4=CC=CC=C34)C[C@@H]2CS(=O)(=O)NC)C2=CC(Cl)=CC=C2C1=O |a:7,22|': 1.3,\n",
       " 'O=C(O)C1=CC(Cl)=CC=C1NS(=O)(=O)C1=CC=C(OC2=CC=CC=C2Cl)C=C1': 3.0,\n",
       " 'C[C@H]1CN(C2=CN=CC3=CC=CC=C23)C(=O)[C@@]12CN(CC1=CC=NN1)C(=O)C1=CC=C(F)C=C12': 2.0,\n",
       " 'CC(C)NC(=O)[C@H](NC1=CC=C2CNCC2=C1)C1=CC(Cl)=CC2=C1N=C(C1=CC=CC=C1)N2 |o1:6|': 2.8,\n",
       " 'CCON=CC1=CC=C(OCCC2CCN(C3=CC=C(C)N=N3)CC2)C=C1': 4.4,\n",
       " 'CC(C)[C@H](NC1=NC=NC2=C1C=C(C1=CN(CC(N)=O)N=C1)N2)C1=CC=C2OCCOC2=N1 |o1:3|': 2.4,\n",
       " 'O=C(NC1=CC=C2CNCC2=C1)C1=CC(Br)=CC2=C1N=C(C1=CC=CC=C1)N2': 3.6,\n",
       " 'CN(C)C(=O)C1=NOC(CCCOC2=CC=C3CCCCC3=C2F)=C1': 4.2,\n",
       " 'N#CCCNC(=O)[C@H](NC1=CC=C2CNCC2=C1)C1=CC(Cl)=CC(C2CC2)=C1 |&1:7|': 0.6,\n",
       " 'CN1N=CC(C2=CC3=C(N[C@H](C4=CC=C5OCCOC5=N4)C(C)(C)C)N=CN=C3N2)=C1C#N |&1:10|': 2.7,\n",
       " 'NCC1=CC=CC(NC(=O)[C@H](NC(=O)OCC2=CC=CC=C2)C2CCCCC2)=C1 |&1:10|': 2.0,\n",
       " 'CNCC1=CC(C2=CC3=C(N[C@H](C4=CC=C5CCCS(=O)(=O)C5=C4)C(C)C)N=CN=C3N2)=CO1 |&1:11|': 2.1,\n",
       " 'C=CC[C@H]1NCC2=CC(NC(=O)C3=CC(F)=CC4=C3C=NN4)=CC=C21 |&1:3|': 1.7,\n",
       " 'CNC(=O)[C@H](NC1=CC=CC(C2=NNN=N2)=C1)C1=CC(Cl)=CC2=C1C=NN2 |&1:4|': 0.3,\n",
       " 'N#C[C@H](NC1=CC=C2CNCC2=C1)C1=CC(Cl)=CC2=C1C=NN2 |&1:2|': 0.9,\n",
       " 'NCCC1=CC=C(NC(=O)C2=CC(Cl)=CC(NC(=O)OCC3=CC=CC=C3)=C2)C=C1': 2.9,\n",
       " 'CC(C)[C@H](NC1=NC=NC2=C1C=C(C1=CN(CC(=O)N(C)C)N=C1)N2)C1=CC=C2CCCS(=O)(=O)C2=C1 |o1:3|': 2.2,\n",
       " 'CN(C)C(=O)C1=NOC(CCCOC2=CC=C(C3=NOC(C4CC4)=N3)C=C2)=C1': 3.6,\n",
       " 'O=C(NC1=C2NC=C(C(=O)N[C@H]3C4=CC=CC=C4C[C@H]3C(=O)O)C2=CC=C1)NC1CC1 |&1:11,19|': -0.05,\n",
       " 'C[C@H]1CN(C[C@H](O)CNC(=O)C2=CC=C3COB(O)C3=C2)CCO1 |&1:1,&2:5|': 0.0,\n",
       " 'O=C(NCC(F)F)[C@H](NC1=CC=C2CNCC2=C1)C1=CC(Cl)=CC(C2CC2)=C1 |o1:7|': 1.4,\n",
       " 'C[C@H]1CN(C2=CN=CC3=CC=CC=C23)C(=O)[C@@]12CN(CCN1CCOCC1)C(=O)C1=CC=C(Cl)C=C12': 1.8,\n",
       " 'CCNC(=O)C1=CC2=C(N[C@H](C3=CC=C4OCCOC4=C3)C(C)C)N=CN=C2N1 |o1:10|': 3.6,\n",
       " 'COC1=CC=C(C2=NN=C(SC3=CC(C4=CC=CC=C4)=NC4=NC=NN34)O2)C=C1': 4.0,\n",
       " 'CCNC(=O)C1=CC2=C(N[C@H](C3=CC=C4CCCS(=O)(=O)C4=C3)C(C)C)N=CN=C2N1 |&1:10|': 2.8,\n",
       " 'CNC(=O)C1=CNC2=NC=NC(N[C@H](C3=CC=C4CCCS(=O)(=O)C4=C3)C(C)C)=C12 |&1:13|': 2.5,\n",
       " 'O=C(O)CN1N=CC2=CC(C3=CC(Cl)=CC(NC(=O)OCC4=CC=CC=C4)=C3)=CC=C21': 2.6,\n",
       " 'CNCCN1C[C@@]2(C(=O)N(C3=CN=CC4=CC=CC=C34)C[C@@H]2C)C2=CC(F)=CC=C2C1=O': 0.0,\n",
       " 'O=C(NC1=CC=C2CNCC2=C1)C1=CC(Cl)=CC2=CC=NC=C12': 0.6,\n",
       " 'NCC1=CC=CC(NC(=O)[C@H](NC(=O)OCC2=CC=CC=C2)C(C2CCC2)C2CCC2)=C1 |&1:10|': 2.5,\n",
       " 'O=C(NC1=CC2=C(C=C1C1CC1)CNC2)C1=CC(F)=CC2=C1C=NN2': 0.7,\n",
       " 'O=C(N[C@H]1[C@H]2CCCCC[C@H]2[C@H]1C(=O)NC1=CC=CC(C2CCNCC2)=C1)OCC1=CC=CC=C1 |&1:3,4,10,11|': 2.8,\n",
       " 'CC(C)[C@H](NC1=NC=NC2=C1C=C(C(=O)N[C@@H]1CCN(C)C1)N2)C1=CC=C2CCCS(=O)(=O)C2=C1 |o1:3|': 1.6,\n",
       " 'O=C(NC1=CC(Br)=C2CNCC2=C1)C1=CC(F)=CC2=C1C=NN2': 1.8,\n",
       " 'CCOC1=NOC2=CC(OCCC3CCN(C4=CC=C(C)N=N4)CC3)=CC=C12': 3.0,\n",
       " 'CC1=CC(OCC2=CC=CC=C2)=CC=C1NS(=O)(=O)C1=CC=C(Cl)C=C1C(=O)O': 2.7,\n",
       " 'CN1N=CC(C2=CC3=C(N[C@H](C4=CC=C5OCCOC5=C4)C(C)(C)C)N=CN=C3N2)=C1C#N |&1:10|': 2.9,\n",
       " 'CNC(=O)CN1C=C(C2=CC3=C(N[C@H](C4=CC=C5CCCS(=O)(=O)C5=C4)C(C)C)N=CN=C3N2)C=N1 |&1:13|': 2.4,\n",
       " 'CN(C1=CC=C2CNCC2=C1)[C@H](C(=O)NCC(F)F)C1=CC(Cl)=CC(C2CC2)=C1 |&1:11|': 1.6,\n",
       " 'O=C1NC(=O)[C@H](CC2=NC3=C(COCC3)S2)C2=CC=CC=C12 |&1:5|': 0.6,\n",
       " 'CC(C)[C@H](NC1=NC=NC2=C1C=CN2)C1=CC=C2OCCS(=O)(=O)C2=C1 |&1:3|': 2.6,\n",
       " 'CC(C)[C@H](NC1=NC=NC2=C1C=C(C1=CN(CC(N)=O)N=C1)N2)C1=CC=C2CCCS(=O)(=O)C2=C1 |o1:3|': 2.0,\n",
       " 'COC1=CC(Cl)=CC([C@H](NC2=CC=C3CNCC3=C2)C(=O)NCC(F)F)=C1 |&1:8|': 0.5,\n",
       " 'ClC1=CC=C2NC=C(CC3=CC=C(C4=NNN=N4)C=C3)C2=C1': 2.1,\n",
       " 'COC1=CC=C([C@H](NC(=O)C2=C3C=CNC3=NC=N2)C(C)C2=NN=NN2)C=C1 |&1:6|': 0.0,\n",
       " 'COC1=CC=C(C2=NN=C(SC3=CC(C)=NC4=NC=NN34)O2)C=C1': 2.4,\n",
       " 'CC1=CC=C(C2=NN=C(SC3=CC(C4=CC=CC=C4)=NC4=NC=NN34)N2C)C=C1': 3.0,\n",
       " 'CC(C)[C@H](NC1=NC=NC2=C1C=C(C1=C(C#N)N(C)N=C1)N2)C1=CC=C2OCCOC2=N1 |o1:3|': 3.9,\n",
       " 'O=C(NC1=CC2=C(C=C1Br)CNC2)C1=CC(F)=CC2=C1C=NN2': 1.1,\n",
       " 'CNC(=O)C1=CC2=C(N[C@H](C3=CC=C4CCCS(=O)(=O)C4=C3)C(C)C)N=CN=C2N1 |o1:9|': 2.4,\n",
       " 'CNC(=O)CN1C[C@@]2(C(=O)N(C3=CN=CC4=CC=CC=C34)C[C@@H]2CNC2=CN=C(C)S2)C2=CC(Cl)=CC=C2C1=O |a:7,22|': 1.9,\n",
       " 'CNC(=O)CN1C[C@@]2(C(=O)N(C3=CN=CC4=CC=CC=C34)C[C@@H]2CNC2=C(C)N=CS2)C2=CC(Cl)=CC=C2C1=O |a:7,22|': 2.1,\n",
       " 'C[C@H]1CN(C2=CN=CC3=CC=CC=C23)C(=O)[C@@]12CN(CC1=CC=NN1C)C(=O)C1=CC=C(F)C=C12': 2.0,\n",
       " 'NCC1=CC(C(=O)O)=CC([C@@H]2C[C@H]2C2=CC(Cl)=CC(NC(=O)OCC3=CC=CC=C3)=C2)=C1 |&1:10,12|': 2.7,\n",
       " 'CCN1C(C)=NN=C1SC1=CC(C)=NC2=NC=NN12': -0.5,\n",
       " 'O=C(NC1=CC(Cl)=CC([C@H](NC2=CC=CC(C3=NNN=N3)=C2)C(=O)NCC2=CC=CC=C2)=C1)OCC1=CC=CC=C1 |&1:9|': 3.7,\n",
       " 'CC(C)[C@H](NC1=NC=NC2=C1C=CN2)C1=CC=C2CCCS(=O)(=O)C2=C1 |o1:3|': 2.7,\n",
       " 'CNC(=O)CN1C[C@@]2(C(=O)N(C3=CN=CC4=CC=CC=C34)C[C@@H]2CS(=O)(=O)N(C)C)C2=CC(Cl)=CC=C2C1=O': 1.6,\n",
       " 'CNC(=O)C1=CC2=C(N[C@H](C3=CC=C4OCC(=O)NC4=C3)C(C)C)N=CN=C2N1 |o1:9|': 2.9,\n",
       " 'C=CC[C@H](NC1=CC=CC(C2=NNN=N2)=C1)C1=CC(Cl)=CC(NC(=O)OCC2=CC=CC=C2)=C1 |&1:3|': 4.1,\n",
       " 'C[C@H]1CN(C2=CN=CC3=CC=CC=C23)C(=O)[C@@]12CN(CC1=NN=NN1C)C(=O)C1=CC=C(F)C=C12 |a:1,16|': 1.5,\n",
       " 'NCC1=CC=CC(NC(=O)C2=CC(OCC3=CC=CC=C3)=CC=C2CNC(=O)OCC2=CC=CC=C2)=C1': 2.8,\n",
       " 'C[C@H]1CN(C2=CN=CC3=CC=CC=C23)C(=O)[C@@]12CN(CC1=CC(O)=NC=N1)C(=O)C1=CC=C(F)C=C12': 0.8,\n",
       " 'O=C(NC1=CC(Cl)=CC(C(=O)NC2=CC=CC(C3=NN=NN3)=C2)=C1)OCC1=CC=CC=C1': 3.7,\n",
       " 'CC1=CC([C@H](NC2=CC=C3CNCC3=C2)C(=O)NCC(F)F)=CC(C(F)(F)F)=C1 |&1:4|': 1.0,\n",
       " 'CNC(=O)CN1C[C@@]2(C(=O)N(C3=CN=CC4=CC=CC=C34)C[C@@H]2CNC2=CN=CS2)C2=CC(Cl)=CC=C2C1=O |a:7,22|': 1.8,\n",
       " 'O=C(NC1=CC=CC(B(O)O)=C1)[C@H]1CCN2CCC[C@H]2C1 |&1:12,&2:19|': 0.3,\n",
       " 'CN(C)C(=O)C1=NOC(CCCOC2=CC=CC(F)=C2)=C1': 2.7,\n",
       " 'NC1=NN=C2C=CC(C3=CC=C4NC(=O)CNC4=C3)=CN12': 0.8,\n",
       " 'CCOC1=CC=CC(C2=CC=C(S(=O)(=O)NC3=CC=C(Cl)C=C3C(=O)O)C=C2)=C1': 2.8,\n",
       " 'CC(C)[C@H](NC1=NC=NC2=C1C=C(C1=C(C#N)N(C)N=C1)N2)C1=CC=C2OCCOC2=C1 |&1:3|': 3.0,\n",
       " 'C[C@H]1CN(C2=CN=CC3=CC=CC=C23)C(=O)[C@@]12CN(CC1=COC=N1)C(=O)C1=CC=C(F)C=C12': 1.9,\n",
       " 'CC(C)[C@@H](NC1=NC=NC2=C1C=C(C1=C(C#N)N(C)N=C1)N2)C1=CC=C2OCCOC2=C1': 3.4,\n",
       " 'C[C@H]1CN(C2=CN=CC3=CC=CC=C23)C(=O)[C@@]12CN(CC1=NC=CN1)C(=O)C1=CC=C(F)C=C12': 2.1,\n",
       " 'CC1=NN=C(SC2=CC(C3=CC=CC=C3)=NC3=NC=NN23)O1': 1.8,\n",
       " 'NCC1=CC=CC(NC(=O)C2=CC=CN3C=C(CN4CCCC4)N=C23)=C1': 0.2,\n",
       " 'COCC1=CC(Cl)=CC([C@H](NC2=CC=C3CNCC3=C2)C(=O)NCC(F)F)=C1 |&1:9|': 0.2,\n",
       " 'CNC(=O)C1=CNC2=NC=NC(N[C@H](C3=CC=C4OCCOC4=C3)C(C)C)=C12 |&1:13|': 3.6,\n",
       " 'NCC1=CC(Cl)=CC(C(=O)NC2=CC=C3CNCC3=C2)=C1': 2.0,\n",
       " 'CCN1C(C)=NN=C1SC1=CC(C2=CC=CC=C2)=NC2=NC=NN12': 1.4,\n",
       " 'CO[C@H]1C[C@H](N2N=CC3=C(C(=O)NC4=CC=C5CNCC5=C4)C=C(Cl)C=C32)C1': 1.5,\n",
       " 'COC1=CC=CC(C2=NN=C(SC3=CC(C4=CC=CC=C4)=NC4=NC=NN34)O2)=C1': 4.1,\n",
       " 'CNC(=O)CN1C[C@@]2(C(=O)N(C3=CN=CC4=CC=CC=C34)C[C@@H]2CC2=NNN=N2)C2=CC(Cl)=CC=C2C1=O': -0.7,\n",
       " 'O=C(NC1=CC(Cl)=CC(C(=O)NC2=CC=C3CNCC3=C2)=C1)OCC1=CC=CC=C1': 2.8,\n",
       " 'CO[C@@H](C)CN1C[C@H](C(=O)NC2=CN=CC3=CC=CC=C23)C2=CC(Cl)=CC=C2C1=O |o1:7|': 2.2,\n",
       " 'CNC(=O)C1(N2C[C@@]3(C(=O)N(C4=CN=CC5=CC=CC=C45)C[C@@H]3C)C3=CC(F)=CC=C3C2=O)CC1': 1.2,\n",
       " 'CNC(=O)C1=CC2=C(N[C@H](C3=CC=C4OCC(=O)NC4=C3)C(C)C)N=CN=C2N1 |&1:9|': 2.8,\n",
       " 'CNC(=O)[C@H](NC1=CC=C2CNCC2=C1)C1=CC(Cl)=CC2=C1N=C(C1=CC=CC=C1)N2 |&1:4|': 1.8,\n",
       " 'CCNC(=O)C1=CC2=C(N[C@H](C3=CC=C4OCCS(=O)(=O)C4=C3)C(C)C)N=CN=C2N1 |&1:10|': 2.9,\n",
       " 'N#C[C@H](NC1=CC=CC(C2=NNN=N2)=C1)C1=CC(Cl)=CC(NC(=O)OCC2=CC=CC=C2)=C1 |&1:2|': 3.2,\n",
       " 'CC1=CC(C2=NOC(C(F)(F)F)=N2)=CC=C1OCCCC1=CC(C(=O)N2CC[C@@H](O)C2)=NO1 |a:28|': 4.4,\n",
       " 'O=C(NC1=CC=C2CNCC2=C1)C1=CC(F)=CC(C2=CNN=C2)=C1': 0.7,\n",
       " 'CN[C@H](C)CN1C[C@H](C(=O)NC2=CN=CC3=CC=CC=C23)C2=CC(Cl)=CC=C2C1=O |&1:7|': 0.8,\n",
       " 'N#C[C@H](NC1=CC=CC(C(=O)O)=C1)C1=CC(Cl)=CC2=C1C=NN2 |&1:2|': 0.6,\n",
       " 'CNC(=O)CN1C[C@@]2(C(=O)N(C3=CN=CC4=CC=CC=C34)C[C@@H]2CN2C=CN=N2)C2=CC(F)=CC=C2C1=O': 0.5,\n",
       " 'C=CC[C@H](NC1=CC=C(C2=NNN=N2)C=C1)C1=CC(Cl)=CC(NC(=O)OCC2=CC=CC=C2)=C1 |&1:3|': 3.9,\n",
       " 'CC(C)[C@H](NC1=NC=NC2=C1C=C(C1=CN(CC(=O)N(C)C)N=C1)N2)C1=CC=C2OCCOC2=C1 |&1:3|': 2.3,\n",
       " 'CC1=NC=CN1C[C@H](C)CNC(=O)C1=CC=C2COB(O)C2=C1 |&1:7|': 0.2,\n",
       " 'CNC(=O)CN1C[C@@]2(C(=O)N(C3=CN=CC4=CC=CC=C34)C[C@@H]2CNC2=CN(C)N=C2)C2=CC(Cl)=CC=C2C1=O': 1.2,\n",
       " 'O=C(NC1=CC=C2CNCC2=C1)C1=CC(Cl)=CC2=C1C=NN2': 0.9,\n",
       " 'O=C(O)C1=CC(Cl)=CC=C1NS(=O)(=O)C1=CC=C(C2=CC=CC=C2Cl)C=C1': 3.6,\n",
       " 'COC1=CC=C(CNC(=O)NC2=CNC(=O)C3=CC=NC=C23)C=N1': 0.7,\n",
       " 'CN(C)C(=O)C1=NOC(CCCOC2=CC=C(F)C=C2)=C1': 2.6,\n",
       " 'C#CCCCCC1=CC=C(OCCCC2=CC(C(=O)N(C)C)=NO2)C=C1': 4.4,\n",
       " 'C[C@H]1CN(C2=CN=CC3=CC=CC=C23)C(=O)[C@@]12CN(CC1=CNN=C1)C(=O)C1=CC=C(F)C=C12': 1.8,\n",
       " 'NCC1=CC=CC(NC(=O)C2=CC(Cl)=CC(NC(=O)OCC3=CC=CC=C3)=C2)=C1': 2.7,\n",
       " 'CNC(=O)C1=CC=CC(C2=CC3=C(N[C@H](C4=CC=C5CCCS(=O)(=O)C5=C4)C(C)C)N=CN=C3N2)=C1 |o1:14|': 3.7,\n",
       " 'CO[C@@H](C)CN1C[C@@]2(C(=O)N(C3=CN=CC4=CC=CC=C34)C[C@@H]2C)C2=CC(F)=CC=C2C1=O': 2.0,\n",
       " 'CCC1=C(C2=CC=C(Cl)C=C2)SC(C(=O)NC2=CC=CC(CN)=C2)=C1': 4.3,\n",
       " 'OCC#C[C@H](NC1=CC=C2CNCC2=C1)C1=CC(Cl)=CC2=C1C=NN2 |&1:4|': 0.5,\n",
       " 'O=C(NCC(F)F)[C@H](NC1=CC=C2CNCC2=C1)C1=CC(Cl)=CC2=C1OC=C2 |&1:7|': 0.6,\n",
       " 'O=C(NCC1=CC=CC=N1)NC1=CNC(=O)C2=CC=C(F)C=C12': 1.0,\n",
       " 'C[C@H]1CN(C2=CN=CC3=CC=CC=C23)C(=O)[C@@]12CN(CC(=O)NCC1(F)CC1)C(=O)C1=CC=C(F)C=C12': 1.7,\n",
       " 'CNC(=O)CN1C[C@]2(CCN(C3=CN=CC4=CC=C(OC[C@H](O)CN(C)C)C=C34)C2=O)C2=CC(Cl)=CC=C2C1=O |&1:7,&2:21|': 0.19,\n",
       " 'CNC(=O)[C@@H](C)N1C[C@@]2(C(=O)N(C3=CN=CC4=CC=CC=C34)C[C@@H]2C)C2=CC(F)=CC=C2C1=O': 1.6,\n",
       " 'O=C(NC1=CC2=C(CNC2)C(C2=CCOCC2)=C1)C1=CC(F)=CC2=C1C=NN2': 0.9,\n",
       " 'CC(C)[C@H](NC1=NC=NC2=C1C=C(C1=CN(C)N=C1)N2)C1=CC=C2CCCS(=O)(=O)C2=C1 |o1:3|': 2.9,\n",
       " 'CC(C)[C@H](NC1=NC=NC2=C1C=CN2)C1=CC=C2OCCOC2=N1 |&1:3|': 2.8,\n",
       " 'CNC(=O)CN1C=C(C2=CC3=C(N[C@H](C4=CC=C5OCCOC5=C4)C(C)C)N=CN=C3N2)C=N1 |&1:13|': 2.9,\n",
       " 'CN1C=NC(CN2C[C@]3(CCN(C4=CN=CC5=CC=CC=C45)C3=O)C3=CC(Cl)=CC=C3C2=O)=N1 |o1:8|': 1.6,\n",
       " 'CC1=CN=C(CN2C[C@@]3(C(=O)N(C4=CN=CC5=CC=CC=C45)C[C@@H]3C)C3=CC(F)=CC=C3C2=O)C=N1': 2.0,\n",
       " 'CN1C=CC(CN2C[C@]3(CCN(C4=CN=CC5=CC=CC=C45)C3=O)C3=CC(Cl)=CC=C3C2=O)=N1 |o1:8|': 2.4,\n",
       " 'CNC(=O)[C@H](NC1=CC(CN)=CC(C2=NNN=N2)=C1)C1=CC(Cl)=CC(C2CC2)=C1 |&1:4|': 1.5,\n",
       " 'CNCC1=CC(C2=CC3=C(N[C@H](C4=CC=C5CCNS(=O)(=O)C5=C4)C(C)C)N=CN=C3N2)=CO1 |&1:11|': 1.9,\n",
       " 'CNC(=O)CN1C[C@@]2(C(=O)N(C3=CN=CC4=CC=CC=C34)C[C@@H]2CS(=O)(=O)NC)C2=CC(F)=CC=C2C1=O': 0.7,\n",
       " 'COCCNC(=O)C1=CNC2=NC=NC(N[C@H](C3=CC=C4CCCS(=O)(=O)C4=C3)C(C)C)=C12 |&1:16|': 2.8,\n",
       " 'COCCNC(=O)[C@H](NC1=CC=C2CNCC2=C1)C1=CC(Cl)=CC(C2CC2)=C1 |o1:7|': 1.0,\n",
       " 'CN1C(SC2=CC(C3=NOC=C3)=NC3=NC=NN23)=NN=C1C1=CC=C(Cl)C=C1': 2.0,\n",
       " 'CC(C)C1=NC2=C(C(=O)NC3=CC=CC(CN)=C3)C=CC=C2N1': 1.9,\n",
       " 'CNCC1=CC(C2=CC3=C(N[C@H](C4=CC=C5CCCS(=O)(=O)C5=C4)C(C)C)N=CN=C3N2)=CO1 |o1:11|': 2.1,\n",
       " 'CC(C)[C@H](NC1=NC=NC2=C1C=C(C1=CN(CC(=O)N(C)C)N=C1)N2)C1=CC=C2OCCOC2=C1 |o1:3|': 3.0,\n",
       " 'CC1CCC2(CC1)CCN(C(=O)CC1=CN=CC3=CC=CC=C13)C2': 3.8,\n",
       " 'CCOC(=O)C1=CC=C(OCCC2CCN(C3=CC=C(C)N=N3)CC2)C=C1': 4.1,\n",
       " 'CC(C)[C@H](NC1=NC=NC2=C1C=CN2)C1=CC=C2OCC(=O)NC2=C1 |o1:3|': 1.8,\n",
       " 'C[C@H]1CN(C2=CN=CC3=CC=CC=C23)C(=O)[C@@]12CN(CC(=O)NCC1=NN(C)C=C1)C(=O)C1=CC=C(Cl)C=C12': 1.8,\n",
       " 'CC(C)[C@H](NC1=NC=NC2=C1C=C(C1=CN(CC(N)=O)N=C1)N2)C1=CC=C2OCC(=O)NC2=C1 |&1:3|': 2.5,\n",
       " 'CC(C)[C@H](NC1=NC=NC2=C1C=C(C1=C(C#N)N(C)N=C1)N2)C1=CC=C2CCCS(=O)(=O)C2=C1 |&1:3|': 3.6,\n",
       " 'O=C1C2=CC=C(Cl)C=C2[C@@]2(CN1CCN1CCOCC1)C(=O)N(C1=CN=CC3=CC=CC=C13)C[C@@H]2CNC1=NC=CC=N1 |a:9,34|': 1.9,\n",
       " 'CNC(=O)CN1C[C@]2(C(=O)N(C3=CN=CC4=CC=CC=C34)C[C@H]2CC2CC2)C2=CC(Cl)=CC=C2C1=O |o1:7,22|': 2.3,\n",
       " 'CC1=NN(C)C=C1C1=CC2=C(N[C@H](C3=CC=C4CCCS(=O)(=O)C4=C3)C(C)C)N=CN=C2N1 |o1:12|': 3.1,\n",
       " 'COC1=CC=C(C(=O)NC2=CC=CC(/C=C3/C(=O)NC(=O)C4=CC=CC=C34)=C2)C=C1': 3.6,\n",
       " 'C[C@H]1CN(C2=CN=CC3=CC=CC=C23)C(=O)[C@@]12CN(CC1=CC=NN=C1)C(=O)C1=CC=C(F)C=C12 |a:1,16|': 1.2,\n",
       " 'CC1=CC=C2OC(SC3=CC(C4=CC=CC=C4)=NC4=NC=NN34)=NC2=C1': 4.4,\n",
       " 'CC1=CC(C2=NOC(C(F)(F)F)=N2)=CC=C1OCCCC1=NN=CO1': 4.0,\n",
       " 'CC(C)[C@H](NC1=NC=NC2=C1C=CN2)C1=CC=C2OCCOC2=C1 |o1:3|': 3.0,\n",
       " 'CNC(=O)C1=CC2=C(N[C@H](C3=CC=C4OCCOC4=C3)C(C)C)N=CN=C2N1 |&1:9|': 2.76,\n",
       " 'CN1N=NC(CN2C[C@]3(CCN(C4=CN=CC5=CC=CC=C45)C3=O)C3=CC(Cl)=CC=C3C2=O)=N1 |o1:8|': 1.9,\n",
       " 'CC(C)[C@H](NC1=NC=NC2=C1C=C(C1=C(C#N)N(C)N=C1)N2)C1=CC=C2CCCS(=O)(=O)C2=C1 |o1:3|': 3.7,\n",
       " 'N#CC1=CC2=C(C=C1NC(=O)C1=CC(F)=CC3=C1C=NN3)CNC2': 0.6,\n",
       " 'NCC1=CC=CC(CNC(=O)[C@H](NC(=O)OCC2=CC=CC=C2)C2=CC=C(OCC3=CC=CC=C3)C=C2)=C1 |&1:11|': 2.7,\n",
       " 'ClC1=CC=C(C2=NN=C(SC3=CC(C4=CC=CC=C4)=NC4=NC=NN34)O2)C=C1': 4.2,\n",
       " 'COC1=CC(C2=CC(NC(=O)C3=CC(F)=CC4=C3C=NN4)=CC3=C2CNC3)=CC=N1': 2.0,\n",
       " 'O=C(NC1=CC2=C(CNC2)C(C2=CCS(=O)(=O)CC2)=C1)C1=CC(F)=CC2=C1C=NN2': -0.1,\n",
       " 'CC1=CC(C2=NOC(C(F)(F)F)=N2)=CC=C1COCCC1=CC(C(=O)N(C)C)=NO1': 3.5,\n",
       " 'CNC(=O)CN1C[C@@]2(C(=O)N(C3=CN=CC4=CC=CC=C34)C[C@@H]2CN2C=CC=N2)C2=CC(Cl)=CC=C2C1=O': 1.9,\n",
       " 'CN1C=C(NC(=O)NCC2=CC=CC=N2)C2=CN=CC=C2C1=O': 0.3,\n",
       " 'N#CC1=CC=CC(C2=NC3=C(C(=O)NC4=CC=C5CNCC5=C4)C=C(F)C=C3N2)=C1': 2.0,\n",
       " 'C=CC(=O)N1CCCC2=C1C=CC=C2N(CC1=CC=CC(Cl)=C1)C(=O)CC1=CN=CC2=CC=CC=C12': 3.3,\n",
       " 'CC1=CC(NC(=O)NC2=CNC(=O)C3=CC=C(F)C=C23)=NO1': 1.9,\n",
       " 'O=C(NCC1=CC=CC=N1)NC1=CNC(=O)C2=CC(Cl)=CC=C12': 1.7,\n",
       " 'COC1=CC(CC2=C(C)ON=C2C2=CC=C(F)C=C2)=NC(N2CCNCC2)=N1': 2.1,\n",
       " 'CC1=CC=CC=C1C1=NN=C(SC2=CC(C3=CC=CC=C3)=NC3=NC=NN23)O1': 3.7,\n",
       " 'CC(C)[C@H](NC1=NC=NC2=C1C=C(C1=CN(CC(N)=O)N=C1)N2)C1=CC=C2OCCOC2=N1 |&1:3|': 2.4,\n",
       " 'CC1=CC(CC(=O)N2CCC[C@H](C(N)=O)C2)=CC=N1 |&1:11|': -0.3,\n",
       " 'CC(C)[C@H](NC1=NC=NC2=C1C=C(C1=C(C#N)N(C)N=C1)N2)C1=CC=C2OCC(=O)NC2=N1 |o1:3|': 3.7,\n",
       " 'CN1N=CC2=C(C(=O)NC3=CC=C4CNCC4=C3)C=C(Br)C=C21': 1.0,\n",
       " 'CC1=NN=C(CCCOC2=CC=C(C3=NOC(C(F)(F)F)=N3)C=C2C)N1': 4.1,\n",
       " 'COC1=CC=CC(Cl)=C1NC(=O)N1CCC[C@H](C(N)=O)C1 |a:16|': 0.3,\n",
       " 'CC(C)[C@H](NC1=NC=NC2=C1C(C(=O)NC1CC1)=CN2)C1=CC=C2CCCS(=O)(=O)C2=C1 |&1:3|': 3.1,\n",
       " 'CO[C@@H](C)CN1C[C@@]2(C(=O)N(C3=CN=CC4=CC=CC=C34)C[C@@H]2C)C2=CC(Cl)=CC=C2C1=O': 2.6,\n",
       " 'CNC(=O)CN1C=C(C2=CC3=C(N[C@H](C4=CC=C5CCCS(=O)(=O)C5=C4)C(C)C)N=CN=C3N2)C=N1 |o1:13|': 2.3,\n",
       " 'NCC1=CC=CC(NC(=O)CN(C(=O)OCC2=CC=CC=C2)C2=CC=C(OCC3=CC=CC=C3)C=C2)=C1': 2.9,\n",
       " 'C[C@H]1CN(C2=CN=CC3=CC=CC=C23)C(=O)[C@@]12CN(CCN1CCN(S(C)(=O)=O)CC1)C(=O)C1=CC=C(Cl)C=C12 |a:1,16|': 1.8,\n",
       " 'CNC(=O)C1=CNC2=NC=NC(N[C@H](C3=CC=C4CCCS(=O)(=O)C4=C3)C(C)C)=C12 |o1:13|': 2.7,\n",
       " 'O=C(NC1=CC=C2CNCC2=C1)C1=CC(Cl)=CC2=C1NN=C2': 1.2,\n",
       " 'CC(C)[C@H](NC1=NC=NC2=C1C=C(C1=CN(C)N=C1)N2)C1=CC=C2CCNS(=O)(=O)C2=C1 |&1:3|': 3.2,\n",
       " 'ClC1=CC=CC(C2=NN=C(SC3=CC(C4=CC=CC=C4)=NC4=NC=NN34)O2)=C1': 4.1,\n",
       " 'CN(C)C(=O)C1=NOC(CCCN2C=CC3=NC(C4=NOC(C(F)(F)F)=N4)=CC=C32)=C1': 2.7,\n",
       " 'O=C(NCC1=CC=CC=N1)NC1=CNC(=O)C2=CC=CN=C12': 0.9,\n",
       " 'O=C(O)C1=CC(Cl)=CC=C1S(=O)(=O)NC1CCN(C2=NC(C3CC3)=CC(C(F)(F)F)=N2)CC1': 2.8,\n",
       " 'CNC(=O)[C@H](NC1=CC=C(C2=NN=NN2)C=C1)C1=CC(Cl)=CC(C2CC2)=C1 |&1:4|': 1.1,\n",
       " 'CNC(=O)CN1C[C@@]2(C(=O)N(C3=CN=CC4=CC=CC=C34)C[C@@H]2CN2N=CN=N2)C2=CC(Cl)=CC=C2C1=O |a:7,22|': 1.1,\n",
       " 'CC(C)[C@H](NC1=NC=NC2=C1C=C(C(=O)N[C@H]1CCN(C)C1)N2)C1=CC=C2CCCS(=O)(=O)C2=C1 |o1:3|': 1.5,\n",
       " 'O=C(NCC(F)F)[C@H](NC1=CC2=C(C=C1Br)CNC2)C1=CC(Cl)=CC(C2CC2)=C1 |&1:7|': 2.9,\n",
       " 'CN1C(=O)C2=CC=C(Cl)C=C2[C@]12CCCN(C1=CN=CC3=CC=CC=C13)C2=O |&1:11|': 1.5,\n",
       " 'COC1=CC=C([C@H](CC2=NN=NN2)NC(=O)C2=NC=NC3=C2C=CN3)C=C1 |o1:6|': -0.5,\n",
       " 'CC(C)[C@H](NC1=NC=NC2=C1C=C(C1=CN(CC(=O)N(C)C)N=C1)N2)C1=CC=C2CCCS(=O)(=O)C2=C1 |&1:3|': 2.1,\n",
       " 'COC(=O)NC1=NC2=CC=C(C(=O)C3=CC=CC=C3)C=C2N1': 2.9,\n",
       " 'CC(C)[C@H](NC1=NC=NC2=C1C=C(C1=CN(CC(N)=O)N=C1)N2)C1=CC=C2OCCOC2=C1 |o1:3|': 2.9,\n",
       " 'CN1N=CC(C2=CC3=C(N[C@H](C4=CC=C5OCCOC5=N4)C(C)(C)C)N=CN=C3N2)=C1C#N |o1:10|': 3.3,\n",
       " 'O=C(NCC(F)F)[C@H](NC1=CN=C2CNCC2=C1)C1=CC(Cl)=CC(C2CC2)=C1 |&1:7|': 1.5,\n",
       " 'CC(C)COC1=NOC2=CC(OCCCC3=CC(C(=O)N(C)C)=NO3)=CC=C12': 4.4,\n",
       " 'CN1N=NN=C1CN1C[C@]2(CCN(C3=CN=CC4=CC=CC=C34)C2=O)C2=CC(Cl)=CC=C2C1=O |o1:9|': 1.9,\n",
       " 'O=C(NC1=CC=CC(B(O)O)=C1)[C@H]1CCN(CC2=CC=CC=C2)C1 |&1:12|': 1.9,\n",
       " 'O=C1NC(=O)[C@@H](CC2=CC=C3OCOC3=C2)C2=CC=CC=C12 |a:5|': 2.4,\n",
       " 'CC(C)NC(=O)[C@H](NC1=CC=C2CNCC2=C1)C1=CC(Cl)=CC2=C1N=C(C1=CC=CC=C1)N2 |&1:6|': 2.9,\n",
       " 'CCNC(=O)C1=CC2=C(N[C@H](C3=CC=C4OCCOC4=C3)C(C)C)N=CN=C2N1 |&1:10|': 3.0,\n",
       " 'CC(C)[C@H](NC1=NC=NC2=C1C(C(N)=O)=CN2)C1=CC=C2OCCOC2=C1 |&1:3|': 3.2,\n",
       " 'O=C1CC2=C(C=CC=C2C(=O)NC2=CC=C3CNCC3=C2)N1': 0.3,\n",
       " 'CCCCNC(=O)[C@H](NC1=CC=C2CNCC2=C1)C1=CC(Cl)=CC(C2CC2)=C1 |&1:7|': 2.3,\n",
       " 'CC1=C(C(=O)NC2=CC([C@H]3CCOC3)=CC=N2)C=C(C2CC2)N1C |&1:9|': 3.0}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "response_i = test_trained_model_inference(dataset[\"validation\"][0]['prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You are an experienced Chemist that provides well-reasoned and detailed responses and excells at predicting ADME properties of molecules. You first think about the reasoning process as an internal monologue and then provide the user with the answer. Respond in the following format: <think>\\n...\\n</think>\\n<answer>\\n...\\n</answer>. Inside <answer>\\n...\\n</answer>, when you finished thinking and certian that it is the most accurate answer you can give, put the final answer in the following format: \\\\boxed{RESULT}, where RESULT is just the final number in float or expression that solves the problem.<｜User｜>The numerical value of LogD (Lipophilicity, like solubility - but then in fatty tissue - LogD is a measure of a molecule's lipophilicity) of the small molecule given it's SMILES 'C[C@H]1CN(C2=CN=CC3=CC=CC=C23)C(=O)[C@@]12CN(CCN1CCOCC1)C(=O)C1=CC=C(Cl)C=C12' is<｜Assistant｜><think>\\nAlright, so I need to determine the LogD value of the given molecule based on its SMILES notation. LogD is a measure of a molecule's lipophilicity, which is important for understanding its bioavailability and pharmacokinetics, especially in terms of how it interacts with biological tissues like fatty tissue.\\n\\nFirst, I'll look at the SMILES string: 'C[C@H]1CN(C2=CN=CC3=CC=CC=C23)C(=O)[C@@]12CN(CCN1CCOCC1)C(=O)C1=CC=C(Cl)C=C12'. This looks like a complex structure with multiple rings and substituents. I notice there are several rings, including a bicyclic structure with an amide group (C(=O)) and a chlorine substituent.\\n\\nLipophilicity is influenced by the molecule's ability to dissolve in lipophilic solvents, which is related to the LogD value. LogD is calculated using the Hammett equation, which considers the molecule's substituents and their effects on the solubility parameter. The equation is: LogD = σ (lipophilicity parameter) + ∑(σ_i * x_i), where σ_i are the substituent constants and x_i are the mole fractions of the substituents.\\n\\nI'll start by identifying the key substituents in the molecule. The presence of the amide groups (C(=O)) and the chlorine atom are likely to increase the LogD value because amides are generally more lipophilic than other groups, and chlorine is a polar substituent but can also contribute to lipophilicity in certain contexts.\\n\\nNext, I'll consider the molecular structure. The molecule has multiple rings, which can affect its overall shape and how it interacts with the environment. The bicyclic structure might influence the molecule's ability to form hydrogen bonds or other interactions that affect solubility.\\n\\nI'll also look for any functional groups that are known to increase or decrease LogD. For example, hydrophobic groups like methyl or ethyl groups increase LogD, while polar groups like hydroxyl or carboxyl can decrease it. However, in this case, the presence of amides and chlorine might counteract some of these effects.\\n\\nTo get a more accurate estimate, I might need to use a tool or software that can calculate LogD based on the SMILES string. Tools like RDKit, Dragon, or other molecular modeling software can perform these calculations. Since I don't have access to these tools right now, I'll have to make an educated guess based on the substituents and the overall structure.\\n\\nConsidering the substituents and the structure, I would estimate that the LogD value is around 2.5 to 3.0. This range suggests that the molecule is moderately lipophilic, which is typical for many organic compounds, especially those with complex structures and multiple functional groups.\\n\\nHowever, without performing a detailed calculation or using a software tool, this is a rough estimate. For a precise LogD value, computational methods are necessary. But based on the information available, I can provide this estimate.\\n</think>\\n\\nThe LogD value of the given molecule, based on its SMILES notation and considering the substituents and structure, is estimated to be around 2.5 to 3.0. This range suggests moderate lipophilicity, typical for complex organic molecules with multiple functional groups.\\n\\n\\\\boxed{2.75}\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"validation\"][0][\"solution\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alisavin/AgenticADMET/openr1/lib/python3.11/site-packages/transformers/trainer.py:3423: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load(os.path.join(checkpoint, OPTIMIZER_NAME), map_location=map_location)\n",
      "Warning: The following arguments do not match the ones in the `trainer_state.json` within the checkpoint directory: \n",
      "\tlogging_steps: 1 (from args) != 10 (from trainer_state.json)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/alisavin/AgenticADMET/notebooks/wandb/run-20250227_022636-6rex2844</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/vladvin-org/huggingface/runs/6rex2844' target=\"_blank\">test</a></strong> to <a href='https://wandb.ai/vladvin-org/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/vladvin-org/huggingface' target=\"_blank\">https://wandb.ai/vladvin-org/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/vladvin-org/huggingface/runs/6rex2844' target=\"_blank\">https://wandb.ai/vladvin-org/huggingface/runs/6rex2844</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alisavin/AgenticADMET/openr1/lib/python3.11/site-packages/transformers/trainer.py:3119: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint_rng_state = torch.load(rng_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parsed correctly 3.8 2.1\n",
      "parsed correctly 1.85 2.1\n",
      "parsed correctly 2.5 2.1\n",
      "parsed correctly 2.8 2.1\n",
      "parsed correctly 3.5 2.1\n",
      "parsed correctly 3.2 2.1\n",
      "parsed correctly 3.5 2.1\n",
      "parsed correctly 2.8 2.1\n",
      "parsed correctly 2.5 1.9\n",
      "parsed correctly 1.25 1.9\n",
      "parsed correctly 3.5 1.9\n",
      "parsed correctly 1.3 1.9\n",
      "parsed correctly 3.8 1.9\n",
      "parsed correctly 4.7 1.9\n",
      "parsed correctly 2.5 1.9\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (16) must match the existing size (2) at non-singleton dimension 0.  Target sizes: [16].  Tensor sizes: [2]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_result \u001b[38;5;241m=\u001b[39m \u001b[43mgrpo_trainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/home/alisavin/AgenticADMET/outputs/2025-02-26/22-18-57/checkpoint-60/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/AgenticADMET/openr1/lib/python3.11/site-packages/transformers/trainer.py:2241\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2239\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2240\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2242\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2245\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2246\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/AgenticADMET/openr1/lib/python3.11/site-packages/transformers/trainer.py:2548\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2541\u001b[0m context \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2542\u001b[0m     functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mno_sync, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[1;32m   2543\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_samples) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2544\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m!=\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED\n\u001b[1;32m   2545\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext\n\u001b[1;32m   2546\u001b[0m )\n\u001b[1;32m   2547\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[0;32m-> 2548\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2550\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2551\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2552\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2553\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2554\u001b[0m ):\n\u001b[1;32m   2555\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2556\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/AgenticADMET/openr1/lib/python3.11/site-packages/transformers/trainer.py:3692\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   3689\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mtrain):\n\u001b[1;32m   3690\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m-> 3692\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3693\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_sagemaker_mp_enabled():\n\u001b[1;32m   3694\u001b[0m     loss_mb \u001b[38;5;241m=\u001b[39m smp_forward_backward(model, inputs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps)\n",
      "File \u001b[0;32m~/AgenticADMET/openr1/lib/python3.11/site-packages/trl/trainer/grpo_trainer.py:627\u001b[0m, in \u001b[0;36mGRPOTrainer._prepare_inputs\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    625\u001b[0m         reward_kwargs \u001b[38;5;241m=\u001b[39m {key: [example[key] \u001b[38;5;28;01mfor\u001b[39;00m example \u001b[38;5;129;01min\u001b[39;00m inputs] \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m keys}\n\u001b[1;32m    626\u001b[0m         output_reward_func \u001b[38;5;241m=\u001b[39m reward_func(prompts\u001b[38;5;241m=\u001b[39mprompts, completions\u001b[38;5;241m=\u001b[39mcompletions, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mreward_kwargs)\n\u001b[0;32m--> 627\u001b[0m         \u001b[43mrewards_per_func\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(output_reward_func, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m    629\u001b[0m \u001b[38;5;66;03m# Gather the reward per function: this part is crucial, because the rewards are normalized per group and the\u001b[39;00m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;66;03m# completions may be distributed across processes\u001b[39;00m\n\u001b[1;32m    631\u001b[0m rewards_per_func \u001b[38;5;241m=\u001b[39m gather(rewards_per_func)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The expanded size of the tensor (16) must match the existing size (2) at non-singleton dimension 0.  Target sizes: [16].  Tensor sizes: [2]"
     ]
    }
   ],
   "source": [
    "train_result = grpo_trainer.train(resume_from_checkpoint=\"/home/alisavin/AgenticADMET/outputs/2025-02-26/22-18-57/checkpoint-60/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_result = grpo_trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Tuned and Frozen Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./test/completions/init_v3_correct_format_16.0/parsed_8c64959f.json\n",
      "./test/completions/tuned_v3_correct_format_16.0/parsed_8c64959f.json\n",
      "[10, 10, 1.7, 0.9000000000000001, 0.9999999999999998, 2.7, 10, 1.4000000000000001, 0.6000000000000001, 2.9000000000000004]\n",
      "[10, 10, 1.7, 0.9000000000000001, 0.9999999999999998, 2.7, 10, 1.4000000000000001, 0.6000000000000001, 2.9000000000000004]\n",
      "./test/completions/init_v3_correct_format_16.0/parsed_beff7dfa.json\n",
      "./test/completions/tuned_v3_correct_format_16.0/parsed_beff7dfa.json\n",
      "[2.0999999999999996, 0.5, 0.9000000000000001, 1.7000000000000002, 0.09999999999999964, 10, 10, 0.9000000000000001, 2.5, 3.8]\n",
      "[2.0999999999999996, 0.5, 0.9000000000000001, 1.7000000000000002, 0.09999999999999964, 10, 10, 0.9000000000000001, 2.5, 3.8]\n",
      "test/completions/init_v3_correct_format_16.0/829e5d68.json\n",
      "./test/completions/tuned_v3_correct_format_16.0/829e5d68.json\n",
      "[10, 0.8, 1.7999999999999998, 0.19999999999999996, 2.0, 1.7999999999999998, 3.8, 0.30000000000000004, 3.2, 10]\n",
      "[10, 0.8, 1.7999999999999998, 0.19999999999999996, 2.0, 1.7999999999999998, 3.8, 0.30000000000000004, 3.2, 10]\n",
      "test/completions/init_v3_correct_format_16.0/31d26d89.json\n",
      "./test/completions/tuned_v3_correct_format_16.0/31d26d89.json\n",
      "[4.2, 5.5, 4.2, 3.9000000000000004, 4.2, 4.9, 3.5, 2.4, 4.5, 4.4]\n",
      "[4.2, 5.5, 4.2, 3.9000000000000004, 4.2, 4.9, 3.5, 2.4, 4.5, 4.4]\n",
      "./test/completions/init_v3_correct_format_16.0/parsed_07748bac.json\n",
      "./test/completions/tuned_v3_correct_format_16.0/parsed_07748bac.json\n",
      "[3.1999999999999997, 10, 2.9, 0.9, 2.1999999999999997, 3.6999999999999997, 10, 2.1999999999999997, 10, 10]\n",
      "[3.1999999999999997, 10, 2.9, 0.9, 2.1999999999999997, 3.6999999999999997, 10, 2.1999999999999997, 10, 10]\n",
      "./test/completions/init_v3_correct_format_16.0/parsed_d1fcb8a5.json\n",
      "./test/completions/tuned_v3_correct_format_16.0/parsed_d1fcb8a5.json\n",
      "[2.4000000000000004, 0.2999999999999998, 0.7999999999999998, 0.9000000000000004, 0.9000000000000004, 0.7000000000000002, 2.0999999999999996, 1.7000000000000002, 1.0, 1.0499999999999998]\n",
      "[2.4000000000000004, 0.2999999999999998, 0.7999999999999998, 0.9000000000000004, 0.9000000000000004, 0.7000000000000002, 2.0999999999999996, 1.7000000000000002, 1.0, 1.0499999999999998]\n",
      "./test/completions/init_v3_correct_format_16.0/parsed_e8858049.json\n",
      "./test/completions/tuned_v3_correct_format_16.0/parsed_e8858049.json\n",
      "[0.73, 0.42999999999999994, 0.07000000000000006, 1.7299999999999998, 1.7299999999999998, 3.4299999999999997, 4.7299999999999995, 0.73, 1.2299999999999998, 2.6799999999999997]\n",
      "[0.73, 0.42999999999999994, 0.07000000000000006, 1.7299999999999998, 1.7299999999999998, 3.4299999999999997, 4.7299999999999995, 0.73, 1.2299999999999998, 2.6799999999999997]\n",
      "./test/completions/init_v3_correct_format_16.0/parsed_42f626fc.json\n",
      "./test/completions/tuned_v3_correct_format_16.0/parsed_42f626fc.json\n",
      "[2.4, 5.0, 2.8, 3.2, 1.2999999999999998, 10, 0.20000000000000018, 0.20000000000000018, 1.2000000000000002, 2.25]\n",
      "[2.4, 5.0, 2.8, 3.2, 1.2999999999999998, 10, 0.20000000000000018, 0.20000000000000018, 1.2000000000000002, 2.25]\n",
      "./test/completions/init_v3_correct_format_16.0/parsed_2fb1c94c.json\n",
      "./test/completions/tuned_v3_correct_format_16.0/parsed_2fb1c94c.json\n",
      "[0.5999999999999999, 10, 1.1, 2.3000000000000003, 3.4, 0.7000000000000002, 0.25, 0.30000000000000027, 0.8999999999999999, 1.4]\n",
      "[0.5999999999999999, 10, 1.1, 2.3000000000000003, 3.4, 0.7000000000000002, 0.25, 0.30000000000000027, 0.8999999999999999, 1.4]\n",
      "./test/completions/init_v3_correct_format_16.0/parsed_ae228591.json\n",
      "./test/completions/tuned_v3_correct_format_16.0/parsed_ae228591.json\n",
      "[1.2999999999999998, 0.2999999999999998, 0.0, 0.20000000000000018, 4.0, 0.3999999999999999, 1.7000000000000002, 0.7000000000000002, 1.7000000000000002, 0.2999999999999998]\n",
      "[1.2999999999999998, 0.2999999999999998, 0.0, 0.20000000000000018, 4.0, 0.3999999999999999, 1.7000000000000002, 0.7000000000000002, 1.7000000000000002, 0.2999999999999998]\n",
      "./test/completions/init_v3_correct_format_16.0/parsed_bb42eb16.json\n",
      "./test/completions/tuned_v3_correct_format_16.0/parsed_bb42eb16.json\n",
      "[10, 3.0999999999999996, 0.6000000000000001, 10, 4.6, 0.8, 2.8, 4.5, 0.8, 2.0999999999999996]\n",
      "[10, 3.0999999999999996, 0.6000000000000001, 10, 4.6, 0.8, 2.8, 4.5, 0.8, 2.0999999999999996]\n",
      "./test/completions/init_v3_correct_format_16.0/parsed_b940e7a8.json\n",
      "./test/completions/tuned_v3_correct_format_16.0/parsed_b940e7a8.json\n",
      "[10, 1.3000000000000003, 0.6000000000000001, 1.9, 1.4, 10, 1.4, 2.4, 0.6000000000000001, 0.8999999999999999]\n",
      "[10, 1.3000000000000003, 0.6000000000000001, 1.9, 1.4, 10, 1.4, 2.4, 0.6000000000000001, 0.8999999999999999]\n",
      "./test/completions/init_v3_correct_format_16.0/parsed_6beca91e.json\n",
      "./test/completions/tuned_v3_correct_format_16.0/parsed_6beca91e.json\n",
      "[0.19999999999999973, 0.19999999999999973, 10, 0.19999999999999973, 2.1, 1.1, 0.8000000000000003, 10, 0.8999999999999999, 0.19999999999999973]\n",
      "[0.19999999999999973, 0.19999999999999973, 10, 0.19999999999999973, 2.1, 1.1, 0.8000000000000003, 10, 0.8999999999999999, 0.19999999999999973]\n",
      "./test/completions/init_v3_correct_format_16.0/parsed_a8441687.json\n",
      "./test/completions/tuned_v3_correct_format_16.0/parsed_a8441687.json\n",
      "[5.5, 10, 4.2, 3.0, 2.0, 0.8, 2.5, 10, 3.2, 2.5]\n",
      "[5.5, 10, 4.2, 3.0, 2.0, 0.8, 2.5, 10, 3.2, 2.5]\n",
      "./test/completions/init_v3_correct_format_16.0/parsed_9895f270.json\n",
      "./test/completions/tuned_v3_correct_format_16.0/parsed_9895f270.json\n",
      "[0.55, 10, 3.0, 2.3, 2.7, 10, 1.3, 1.3, 2.3, 2.5999999999999996]\n",
      "[0.55, 10, 3.0, 2.3, 2.7, 10, 1.3, 1.3, 2.3, 2.5999999999999996]\n",
      "./test/completions/init_v3_correct_format_16.0/parsed_5a16730b.json\n",
      "./test/completions/tuned_v3_correct_format_16.0/parsed_5a16730b.json\n",
      "[0.2999999999999998, 10, 0.6499999999999999, 1.7999999999999998, 0.7999999999999998, 0.2999999999999998, 1.0, 0.2999999999999998, 1.7000000000000002, 3.6]\n",
      "[0.2999999999999998, 10, 0.6499999999999999, 1.7999999999999998, 0.7999999999999998, 0.2999999999999998, 1.0, 0.2999999999999998, 1.7000000000000002, 3.6]\n",
      "./test/completions/init_v3_correct_format_16.0/parsed_e6cbc990.json\n",
      "./test/completions/tuned_v3_correct_format_16.0/parsed_e6cbc990.json\n",
      "[0.30000000000000004, 2.3, 2.5, 2.5, 2.0, 0.6000000000000001, 0.7, 0.050000000000000044, 1.5, 10]\n",
      "[0.30000000000000004, 2.3, 2.5, 2.5, 2.0, 0.6000000000000001, 0.7, 0.050000000000000044, 1.5, 10]\n",
      "./test/completions/init_v3_correct_format_16.0/parsed_dbd310bc.json\n",
      "./test/completions/tuned_v3_correct_format_16.0/parsed_dbd310bc.json\n",
      "[1.7999999999999998, 2.7, 1.7999999999999998, 1.2999999999999998, 1.2999999999999998, 0.2999999999999998, 10, 0.2999999999999998, 2.0, 0.1499999999999999]\n",
      "[1.7999999999999998, 2.7, 1.7999999999999998, 1.2999999999999998, 1.2999999999999998, 0.2999999999999998, 10, 0.2999999999999998, 2.0, 0.1499999999999999]\n",
      "./test/completions/init_v3_correct_format_16.0/parsed_1f9b0d4b.json\n",
      "./test/completions/tuned_v3_correct_format_16.0/parsed_1f9b0d4b.json\n",
      "[1.4000000000000001, 3.6999999999999997, 0.3999999999999999, 0.9000000000000001, 1.4, 1.6, 3.6999999999999997, 0.3999999999999999, 0.30000000000000004, 1.4]\n",
      "[1.4000000000000001, 3.6999999999999997, 0.3999999999999999, 0.9000000000000001, 1.4, 1.6, 3.6999999999999997, 0.3999999999999999, 0.30000000000000004, 1.4]\n",
      "./test/completions/init_v3_correct_format_16.0/parsed_03476906.json\n",
      "./test/completions/tuned_v3_correct_format_16.0/parsed_03476906.json\n",
      "[1.5999999999999996, 1.4000000000000001, 0.7999999999999998, 0.40000000000000013, 2.0, 2.5, 1.2999999999999998, 2.3, 1.2999999999999998, 0.5999999999999996]\n",
      "[1.5999999999999996, 1.4000000000000001, 0.7999999999999998, 0.40000000000000013, 2.0, 2.5, 1.2999999999999998, 2.3, 1.2999999999999998, 0.5999999999999996]\n",
      "./test/completions/init_v3_correct_format_16.0/parsed_c2e5d971.json\n",
      "./test/completions/tuned_v3_correct_format_16.0/parsed_c2e5d971.json\n",
      "[3.4, 0.8999999999999999, 0.8999999999999999, 1.1, 2.8, 0.6000000000000001, 0.3999999999999999, 0.6000000000000001, 0.8000000000000003, 2.1]\n",
      "[3.4, 0.8999999999999999, 0.8999999999999999, 1.1, 2.8, 0.6000000000000001, 0.3999999999999999, 0.6000000000000001, 0.8000000000000003, 2.1]\n",
      "./test/completions/init_v3_correct_format_16.0/parsed_9fbb21ac.json\n",
      "./test/completions/tuned_v3_correct_format_16.0/parsed_9fbb21ac.json\n",
      "[10, 3.63, 4.58, 1.6800000000000002, 0.38, 4.68, 4.38, 4.08, 4.08, 2.38]\n",
      "[10, 3.63, 4.58, 1.6800000000000002, 0.38, 4.68, 4.38, 4.08, 4.08, 2.38]\n",
      "./test/completions/init_v3_correct_format_16.0/parsed_121bbe8f.json\n",
      "./test/completions/tuned_v3_correct_format_16.0/parsed_121bbe8f.json\n",
      "[10, 1.75, 10, 3.2, 3.0, 3.2, 1.8, 2.8, 5.0, 2.5]\n",
      "[10, 1.75, 10, 3.2, 3.0, 3.2, 1.8, 2.8, 5.0, 2.5]\n",
      "./test/completions/init_v3_correct_format_16.0/parsed_3d8afd22.json\n",
      "./test/completions/tuned_v3_correct_format_16.0/parsed_3d8afd22.json\n",
      "[5.3, 0.7000000000000002, 0.7000000000000002, 1.4000000000000004, 0.20000000000000018, 1.0, 1.7999999999999998, 0.7000000000000002, 1.0, 10]\n",
      "[5.3, 0.7000000000000002, 0.7000000000000002, 1.4000000000000004, 0.20000000000000018, 1.0, 1.7999999999999998, 0.7000000000000002, 1.0, 10]\n",
      "./test/completions/init_v3_correct_format_16.0/parsed_4f0bc0b1.json\n",
      "./test/completions/tuned_v3_correct_format_16.0/parsed_4f0bc0b1.json\n",
      "[0.9000000000000004, 3.9000000000000004, 2.9000000000000004, 0.7000000000000002, 0.8000000000000003, 2.1000000000000005, 0.7999999999999998, 0.9000000000000004, 1.6000000000000005, 1.7000000000000002]\n",
      "[0.9000000000000004, 3.9000000000000004, 2.9000000000000004, 0.7000000000000002, 0.8000000000000003, 2.1000000000000005, 0.7999999999999998, 0.9000000000000004, 1.6000000000000005, 1.7000000000000002]\n",
      "test/completions/init_v3_correct_format_16.0/410b69e5.json\n",
      "./test/completions/tuned_v3_correct_format_16.0/410b69e5.json\n",
      "[2.2, 0.8999999999999999, 2.3000000000000003, 2.6, 0.40000000000000013, 0.10000000000000009, 1.1, 2.1, 10, 0.6000000000000001]\n",
      "[2.2, 0.8999999999999999, 2.3000000000000003, 2.6, 0.40000000000000013, 0.10000000000000009, 1.1, 2.1, 10, 0.6000000000000001]\n",
      "test/completions/init_v3_correct_format_16.0/68a3eefe.json\n",
      "./test/completions/tuned_v3_correct_format_16.0/68a3eefe.json\n",
      "[0.5, 1.5, 2.9000000000000004, 10, 1.4999999999999998, 0.20000000000000018, 0.0, 1.2000000000000002, 0.9000000000000004, 2.9000000000000004]\n",
      "[0.5, 1.5, 2.9000000000000004, 10, 1.4999999999999998, 0.20000000000000018, 0.0, 1.2000000000000002, 0.9000000000000004, 2.9000000000000004]\n",
      "./test/completions/init_v3_correct_format_16.0/parsed_f7407c20.json\n",
      "./test/completions/tuned_v3_correct_format_16.0/parsed_f7407c20.json\n",
      "[0.7000000000000002, 10, 0.2999999999999998, 1.9999999999999998, 0.2999999999999998, 0.2999999999999998, 0.2999999999999998, 3.8, 4.3, 10]\n",
      "[0.7000000000000002, 10, 0.2999999999999998, 1.9999999999999998, 0.2999999999999998, 0.2999999999999998, 0.2999999999999998, 3.8, 4.3, 10]\n",
      "./test/completions/init_v3_correct_format_16.0/parsed_ff2058fc.json\n",
      "./test/completions/tuned_v3_correct_format_16.0/parsed_ff2058fc.json\n",
      "[3.0, 1.0, 10, 0.20000000000000018, 0.7999999999999998, 1.2000000000000002, 1.2000000000000002, 0.5, 0.20000000000000018, 4.5]\n",
      "[3.0, 1.0, 10, 0.20000000000000018, 0.7999999999999998, 1.2000000000000002, 1.2000000000000002, 0.5, 0.20000000000000018, 4.5]\n",
      "./test/completions/init_v3_correct_format_16.0/parsed_4120a926.json\n",
      "./test/completions/tuned_v3_correct_format_16.0/parsed_4120a926.json\n",
      "[0.0, 2.0999999999999996, 3.0999999999999996, 0.7, 2.0, 3.0999999999999996, 0.8999999999999999, 0.30000000000000004, 0.30000000000000004, 0.7]\n",
      "[0.0, 2.0999999999999996, 3.0999999999999996, 0.7, 2.0, 3.0999999999999996, 0.8999999999999999, 0.30000000000000004, 0.30000000000000004, 0.7]\n",
      "./test/completions/init_v3_correct_format_16.0/parsed_915e1b30.json\n",
      "./test/completions/tuned_v3_correct_format_16.0/parsed_915e1b30.json\n",
      "[1.0, 0.5, 0.65, 1.2, 3.3, 2.3, 2.3, 10, 10, 2.0]\n",
      "[1.0, 0.5, 0.65, 1.2, 3.3, 2.3, 2.3, 10, 10, 2.0]\n",
      "./test/completions/init_v3_correct_format_16.0/parsed_3e7fd775.json\n",
      "./test/completions/tuned_v3_correct_format_16.0/parsed_3e7fd775.json\n",
      "[1.7599999999999998, 0.9599999999999997, 0.7400000000000002, 0.9900000000000002, 1.7400000000000002, 1.2400000000000002, 1.7400000000000002, 0.5599999999999996, 1.04, 1.8099999999999998]\n",
      "[1.7599999999999998, 0.9599999999999997, 0.7400000000000002, 0.9900000000000002, 1.7400000000000002, 1.2400000000000002, 1.7400000000000002, 0.5599999999999996, 1.04, 1.8099999999999998]\n",
      "./test/completions/init_v3_correct_format_16.0/parsed_c94a83f1.json\n",
      "./test/completions/tuned_v3_correct_format_16.0/parsed_c94a83f1.json\n",
      "[1.7999999999999998, 1.5, 0.0, 1.1, 2.0, 10, 1.5, 0.7999999999999998, 0.0, 2.5]\n",
      "[1.7999999999999998, 1.5, 0.0, 1.1, 2.0, 10, 1.5, 0.7999999999999998, 0.0, 2.5]\n",
      "./test/completions/init_v3_correct_format_16.0/parsed_189835d9.json\n",
      "./test/completions/tuned_v3_correct_format_16.0/parsed_189835d9.json\n",
      "[3.8000000000000003, 2.9, 10, 10, 2.35, 6.1, 2.4, 1.9, 10, 3.1]\n",
      "[3.8000000000000003, 2.9, 10, 10, 2.35, 6.1, 2.4, 1.9, 10, 3.1]\n",
      "test/completions/init_v3_correct_format_16.0/d2360b91.json\n",
      "./test/completions/tuned_v3_correct_format_16.0/d2360b91.json\n",
      "[0.30000000000000004, 2.5999999999999996, 2.0, 1.8, 3.3, 0.5, 10, 3.0, 3.3, 2.8]\n",
      "[0.30000000000000004, 2.5999999999999996, 2.0, 1.8, 3.3, 0.5, 10, 3.0, 3.3, 2.8]\n",
      "./test/completions/init_v3_correct_format_16.0/parsed_8c264d8c.json\n",
      "./test/completions/tuned_v3_correct_format_16.0/parsed_8c264d8c.json\n",
      "[0.9000000000000004, 2.9000000000000004, 0.20000000000000018, 2.6000000000000005, 0.5999999999999996, 1.6000000000000005, 10, 0.9000000000000004, 0.39999999999999947, 0.7000000000000002]\n",
      "[0.9000000000000004, 2.9000000000000004, 0.20000000000000018, 2.6000000000000005, 0.5999999999999996, 1.6000000000000005, 10, 0.9000000000000004, 0.39999999999999947, 0.7000000000000002]\n",
      "./test/completions/init_v3_correct_format_16.0/parsed_8c1682c4.json\n",
      "./test/completions/tuned_v3_correct_format_16.0/parsed_8c1682c4.json\n",
      "[1.4000000000000001, 2.7, 1.2, 1.7, 2.3, 1.2, 1.1, 1.7, 2.7, 1.4000000000000001]\n",
      "[1.4000000000000001, 2.7, 1.2, 1.7, 2.3, 1.2, 1.1, 1.7, 2.7, 1.4000000000000001]\n",
      "./test/completions/init_v3_correct_format_16.0/parsed_4845b0a6.json\n",
      "./test/completions/tuned_v3_correct_format_16.0/parsed_4845b0a6.json\n",
      "[2.7, 1.7, 0.0, 3.0, 10, 3.4000000000000004, 3.0, 1.7, 1.7, 1.9999999999999998]\n",
      "[2.7, 1.7, 0.0, 3.0, 10, 3.4000000000000004, 3.0, 1.7, 1.7, 1.9999999999999998]\n",
      "./test/completions/init_v3_correct_format_16.0/parsed_d643f983.json\n",
      "./test/completions/tuned_v3_correct_format_16.0/parsed_d643f983.json\n",
      "[1.7000000000000002, 0.25, 0.75, 1.3, 1.7000000000000002, 2.0, 0.2999999999999998, 2.0, 1.5, 0.2999999999999998]\n",
      "[1.7000000000000002, 0.25, 0.75, 1.3, 1.7000000000000002, 2.0, 0.2999999999999998, 2.0, 1.5, 0.2999999999999998]\n",
      "./test/completions/init_v3_correct_format_16.0/parsed_33a6eff0.json\n",
      "./test/completions/tuned_v3_correct_format_16.0/parsed_33a6eff0.json\n",
      "[5.2, 4.4, 10, 3.1999999999999997, 5.2, 4.9, 3.9, 2.4, 2.9, 3.6]\n",
      "[5.2, 4.4, 10, 3.1999999999999997, 5.2, 4.9, 3.9, 2.4, 2.9, 3.6]\n",
      "./test/completions/init_v3_correct_format_16.0/parsed_d8142a3b.json\n",
      "./test/completions/tuned_v3_correct_format_16.0/parsed_d8142a3b.json\n",
      "[1.7, 1.7, 0.6000000000000001, 2.4000000000000004, 0.7, 0.5700000000000001, 0.5, 1.9999999999999998, 1.9999999999999998, 2.0999999999999996]\n",
      "[1.7, 1.7, 0.6000000000000001, 2.4000000000000004, 0.7, 0.5700000000000001, 0.5, 1.9999999999999998, 1.9999999999999998, 2.0999999999999996]\n",
      "./test/completions/init_v3_correct_format_16.0/parsed_4760e248.json\n",
      "./test/completions/tuned_v3_correct_format_16.0/parsed_4760e248.json\n",
      "[3.3, 4.6, 0.0, 2.0, 1.5999999999999999, 2.5999999999999996, 10, 3.5, 2.8, 1.0999999999999999]\n",
      "[3.3, 4.6, 0.0, 2.0, 1.5999999999999999, 2.5999999999999996, 10, 3.5, 2.8, 1.0999999999999999]\n",
      "./test/completions/init_v3_correct_format_16.0/parsed_bdc16fd3.json\n",
      "./test/completions/tuned_v3_correct_format_16.0/parsed_bdc16fd3.json\n",
      "[2.8, 2.8, 1.8, 1.05, 1.1, 3.8, 3.8, 0.0, 4.1, 3.0999999999999996]\n",
      "[2.8, 2.8, 1.8, 1.05, 1.1, 3.8, 3.8, 0.0, 4.1, 3.0999999999999996]\n",
      "./test/completions/init_v3_correct_format_16.0/parsed_559ccebe.json\n",
      "./test/completions/tuned_v3_correct_format_16.0/parsed_559ccebe.json\n",
      "[2.2, 1.4, 10, 0.8, 1.5, 0.75, 0.19999999999999996, 10, 0.25, 1.0]\n",
      "[2.2, 1.4, 10, 0.8, 1.5, 0.75, 0.19999999999999996, 10, 0.25, 1.0]\n",
      "./test/completions/init_v3_correct_format_16.0/parsed_a85986fc.json\n",
      "./test/completions/tuned_v3_correct_format_16.0/parsed_a85986fc.json\n",
      "[2.6, 4.8, 10, 10, 1.85, 5.3, 2.6, 5.1, 1.6, 3.8000000000000003]\n",
      "[2.6, 4.8, 10, 10, 1.85, 5.3, 2.6, 5.1, 1.6, 3.8000000000000003]\n",
      "./test/completions/init_v3_correct_format_16.0/parsed_58239f00.json\n",
      "./test/completions/tuned_v3_correct_format_16.0/parsed_58239f00.json\n",
      "[1.3, 2.5, 10, 1.8, 3.5, 1.8, 0.8, 4.8, 1.2, 0.67]\n",
      "[1.3, 2.5, 10, 1.8, 3.5, 1.8, 0.8, 4.8, 1.2, 0.67]\n",
      "./test/completions/init_v3_correct_format_16.0/parsed_1df5063d.json\n",
      "./test/completions/tuned_v3_correct_format_16.0/parsed_1df5063d.json\n",
      "[2.3, 6.1, 0.09999999999999964, 1.5, 1.1999999999999997, 10, 0.7999999999999998, 0.09999999999999964, 2.8, 0.7000000000000002]\n",
      "[2.3, 6.1, 0.09999999999999964, 1.5, 1.1999999999999997, 10, 0.7999999999999998, 0.09999999999999964, 2.8, 0.7000000000000002]\n",
      "./test/completions/init_v3_correct_format_16.0/parsed_3ab19aa9.json\n",
      "./test/completions/tuned_v3_correct_format_16.0/parsed_3ab19aa9.json\n",
      "[2.9, 3.9, 3.1999999999999997, 3.1999999999999997, 5.2, 1.1, 0.65, 0.9, 2.1999999999999997, 0.9]\n",
      "[2.9, 3.9, 3.1999999999999997, 3.1999999999999997, 5.2, 1.1, 0.65, 0.9, 2.1999999999999997, 0.9]\n",
      "mean mae tuned - 2.784876302083333, mean mae - 2.784876302083333\n",
      "median: mean mae tuned - 1.5760416666666666, mean mae - 1.5760416666666666\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "from pathlib import Path\n",
    "import json\n",
    "import hashlib\n",
    "import numpy as np\n",
    "\n",
    "pred_path = \"./test/completions/tuned_v3_correct_format_16.0/*.json\"\n",
    "num_generations = Path(pred_path).parts[-2].split(\"_\")[-1]\n",
    "pths_1 = glob.glob(pred_path)\n",
    "# pth_2 = glob.glob(\"test/not_tuned_pred/*json\")\n",
    "\n",
    "dict_all = {}\n",
    " \n",
    "mean_mae_1 = []\n",
    "mean_mae_2 = []\n",
    "\n",
    "mean_mae_1_median = []\n",
    "mean_mae_2_median = []\n",
    "\n",
    "\n",
    "for pth_i in pths_1:\n",
    "    with open(pth_i, \"r\") as f:\n",
    "        dict_i = json.load(f)\n",
    "    smiles = dict_i[\"smiles\"]\n",
    "    smiles_hash = hashlib.blake2b(smiles.encode('utf-8'), digest_size=4).hexdigest()\n",
    "\n",
    "    pth = f\"./test/completions/init_v3_correct_format_{num_generations}/parsed_{smiles_hash}.json\" if Path(f\"test/completions/init_v3_correct_format_{num_generations}/parsed_{smiles_hash}.json\").exists() else f\"test/completions/init_v3_correct_format_{num_generations}/{smiles_hash}.json\"\n",
    "    with open(pth, \"r\") as f:\n",
    "        dict_i_2 = json.load(f)\n",
    "    \n",
    "    print(pth)\n",
    "    print(pth_i)\n",
    "\n",
    "    dict_all[smiles] = {\n",
    "        \"7BQwen\": {\n",
    "            \"completion\": dict_i_2[\"completion\"], \n",
    "            \"answer_val\": dict_i_2[\"answer_val\"],\n",
    "            \"mae\": dict_i_2[\"mae\"],\n",
    "            \"mae_median\": dict_i_2[\"mae_median\"]\n",
    "        },\n",
    "        \"7BQwenTuned\": {\n",
    "            \"completion\": dict_i[\"completion\"], \n",
    "            \"answer_val\": dict_i[\"answer_val\"],\n",
    "            \"mae\": dict_i[\"mae\"],\n",
    "            \"mae_median\": dict_i[\"mae_median\"]\n",
    "        },\n",
    "        \"gold_val\": dict_i_2[\"gold_val\"],\n",
    "    }\n",
    "    if dict_i_2[\"answer_val\"] is None:\n",
    "        dict_all[smiles][\"7BQwen\"][\"answer_parsed\"] = dict_i_2[\"answer_parsed\"]\n",
    "    if dict_i[\"answer_val\"] is None:\n",
    "        dict_all[smiles][\"7BQwenTuned\"][\"answer_parsed\"] = dict_i_2[\"answer_parsed\"]\n",
    "\n",
    "    if dict_i[\"mae\"] is not None:\n",
    "        mean_mae_1.extend([float(v_i) if v_i is not None else 10 for v_i in dict_i[\"mae\"]])\n",
    "    if dict_i_2[\"mae\"] is not None:\n",
    "        mean_mae_2.append([float(v_i) if v_i is not None else 10 for v_i in dict_i_2[\"mae\"]])\n",
    "    print([float(v_i) if v_i is not None else 10 for v_i in dict_i[\"mae\"]][:10])\n",
    "    print([float(v_i) if v_i is not None else 10 for v_i in dict_i_2[\"mae\"]][:10])\n",
    "    if dict_i[\"mae_median\"] is not None:\n",
    "        mean_mae_1_median.append(float(dict_i[\"mae_median\"]))\n",
    "    if dict_i_2[\"mae_median\"] is not None:\n",
    "        mean_mae_2_median.append(float(dict_i_2[\"mae_median\"]))\n",
    "print(f\"mean mae tuned - {np.mean(mean_mae_1)}, mean mae - {np.mean(mean_mae_2)}\")\n",
    "print(f\"median: mean mae tuned - {np.mean([v_i for v_i in mean_mae_1_median if not np.isnan(v_i)])}, mean mae - {np.mean([v_i for v_i in mean_mae_2_median if not np.isnan(v_i)])}\")\n",
    "\n",
    "with open(f\"./test/completions/all_results_v3_{num_generations}.json\", \"w\") as f:\n",
    "    json.dump(dict_all, f, indent=2)\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openr1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
